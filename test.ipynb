{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "617814e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "from typing import Optional, Tuple, List\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "4707504e",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(42)\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58c13557",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "awkward bunch of math stuff which essentially means it encodes everythings relative and absolute position in the protein sequence\n",
    "\"\"\"\n",
    "\n",
    "def add_positional_encoding(x):\n",
    "    batch_size, seq_len, d_model = x.shape\n",
    "    \n",
    "    # Create positional encoding\n",
    "    pe = torch.zeros(seq_len, d_model, device=x.device)\n",
    "    position = torch.arange(0, seq_len, dtype=torch.float, device=x.device).unsqueeze(1)\n",
    "    div_term = torch.exp(torch.arange(0, d_model, 2, device=x.device).float() * \n",
    "                        (-math.log(10000.0) / d_model))\n",
    "    \n",
    "    pe[:, 0::2] = torch.sin(position * div_term)\n",
    "    pe[:, 1::2] = torch.cos(position * div_term)\n",
    "    \n",
    "    # Add to input and return\n",
    "    return x + pe.unsqueeze(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffca196e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Encodes the model so that the model\n",
    "\n",
    "Preserves relative order and distances between timesteps,\n",
    "\n",
    "And generalizes well, even to unseen timesteps.\n",
    "\"\"\"\n",
    "\n",
    "def create_time_embedding(time, dim):\n",
    "    device = time.device\n",
    "    half_dim = dim // 2\n",
    "    embeddings = math.log(10000) / (half_dim - 1)\n",
    "    embeddings = torch.exp(torch.arange(half_dim, device=device) * -embeddings)\n",
    "    embeddings = time[:, None] * embeddings[None, :]\n",
    "    embeddings = torch.cat((embeddings.sin(), embeddings.cos()), dim=-1)\n",
    "    return embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45f55cb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Each token is projected into three vectors: Query, Key, and Value - attend (Q), how it can be attended to (K), and what info it carries (V)\n",
    "\n",
    "Computes attention scores between all pairs of tokens in the sequence for each head.\n",
    "\n",
    "attention output for each token by aggregating values V weighted by attention scores.\n",
    "\n",
    "Recombines all num_heads outputs back into one tensor with shape [batch_size, seq_len, d_model].\n",
    "\"\"\"\n",
    "def multi_head_attention(x, w_q, w_k, w_v, w_o, dropout_layer, num_heads, mask=None):\n",
    "    batch_size, seq_len, d_model = x.shape\n",
    "    d_k = d_model // num_heads\n",
    "    \n",
    "    # Linear transformations and reshape\n",
    "    Q = w_q(x).view(batch_size, seq_len, num_heads, d_k).transpose(1, 2)\n",
    "    K = w_k(x).view(batch_size, seq_len, num_heads, d_k).transpose(1, 2)\n",
    "    V = w_v(x).view(batch_size, seq_len, num_heads, d_k).transpose(1, 2)\n",
    "    \n",
    "    # Scaled dot-product attention\n",
    "    scores = torch.matmul(Q, K.transpose(-2, -1)) / math.sqrt(d_k)\n",
    "    \n",
    "    if mask is not None:\n",
    "        # Reshape mask to match scores dimensions: [batch_size, 1, 1, seq_len]\n",
    "        mask = mask.unsqueeze(1).unsqueeze(2)  # [batch_size, 1, 1, seq_len]\n",
    "        scores = scores.masked_fill(mask == 0, -1e9)\n",
    "    \n",
    "    attention_weights = F.softmax(scores, dim=-1)\n",
    "    attention_weights = dropout_layer(attention_weights)\n",
    "    \n",
    "    # Apply attention to values\n",
    "    context = torch.matmul(attention_weights, V)\n",
    "    \n",
    "    # Concatenate heads and put through final linear layer\n",
    "    context = context.transpose(1, 2).contiguous().view(batch_size, seq_len, d_model)\n",
    "    \n",
    "    return w_o(context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b1c93f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Applies multi-head attention with residual connection\n",
    "Applies feed-forward network with residual connection\n",
    "Uses layer normalization\n",
    "\"\"\"\n",
    "\n",
    "def transformer_block(x, attention_layers, norm1, norm2, feed_forward, mask=None):\n",
    "    # Self-attention with residual connection\n",
    "    attn_output = multi_head_attention(x, attention_layers['w_q'], attention_layers['w_k'], \n",
    "                                     attention_layers['w_v'], attention_layers['w_o'], \n",
    "                                     attention_layers['dropout'], attention_layers['num_heads'], mask)\n",
    "    x = norm1(x + attn_output)\n",
    "    \n",
    "    # Feed-forward with residual connection\n",
    "    ff_output = feed_forward(x)\n",
    "    x = norm2(x + ff_output)\n",
    "    \n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f83ba19",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "This function embeds the input protein sequence and adds positional encoding, then creates conditioning vectors from the timestep and temperature which get added to every sequence \n",
    "position. It processes this conditioned sequence through multiple transformer blocks, then splits the output into sequence predictions (via output projection) and temperature\n",
    " predictions (via global pooling and a temperature head).\n",
    "\"\"\"\n",
    "\n",
    "def rubisco_diffusion_forward(x, timesteps, temperature, model_components, mask=None):\n",
    "    \"\"\"\n",
    "    RuBisCO Diffusion Model forward pass as a function\n",
    "    \n",
    "    Args:\n",
    "        x: Input sequences [batch_size, seq_len]\n",
    "        timesteps: Diffusion timesteps [batch_size]\n",
    "        temperature: Target temperatures [batch_size, 1]\n",
    "        model_components: Dictionary containing all model layers\n",
    "        mask: Attention mask [batch_size, seq_len]\n",
    "    \"\"\"\n",
    "    batch_size, seq_len = x.shape\n",
    "    d_model = model_components['d_model']\n",
    "    \n",
    "    # Amino acid embeddings with positional encoding\n",
    "    x_embedded = model_components['amino_acid_embedding'](x)  # [batch_size, seq_len, d_model]\n",
    "    x_embedded = add_positional_encoding(x_embedded)\n",
    "    x_embedded = model_components['dropout'](x_embedded)\n",
    "    \n",
    "    # Time and temperature conditioning\n",
    "    time_embed = create_time_embedding(timesteps, d_model)  # [batch_size, d_model]\n",
    "    temp_embed = model_components['temp_embedding'](temperature)  # [batch_size, d_model]\n",
    "    \n",
    "    # Combine conditioning\n",
    "    condition = torch.cat([time_embed, temp_embed], dim=-1)  # [batch_size, 2*d_model]\n",
    "    condition = model_components['condition_proj'](condition)  # [batch_size, d_model]\n",
    "    \n",
    "    # Add conditioning to sequence (broadcast across sequence length)\n",
    "    condition = condition.unsqueeze(1).expand(-1, seq_len, -1)\n",
    "    x_embedded = x_embedded + condition\n",
    "    \n",
    "    # Transformer blocks\n",
    "    hidden = x_embedded\n",
    "    for i in range(len(model_components['transformer_blocks'])):\n",
    "        block_components = model_components['transformer_blocks'][i]\n",
    "        hidden = transformer_block(hidden, block_components['attention'], \n",
    "                                 block_components['norm1'], block_components['norm2'], \n",
    "                                 block_components['feed_forward'], mask)\n",
    "    \n",
    "    # Output projections\n",
    "    sequence_logits = model_components['output_projection'](hidden)  # [batch_size, seq_len, vocab_size]\n",
    "    \n",
    "    # Global pooling for temperature prediction\n",
    "    if mask is not None:\n",
    "        mask_expanded = mask.unsqueeze(-1).expand_as(hidden)\n",
    "        hidden_masked = hidden * mask_expanded\n",
    "        seq_len_actual = mask.sum(dim=1, keepdim=True).float()\n",
    "        pooled = hidden_masked.sum(dim=1) / seq_len_actual  # [batch_size, d_model]\n",
    "    else:\n",
    "        pooled = hidden.mean(dim=1)  # [batch_size, d_model]\n",
    "    \n",
    "    temp_pred = model_components['temperature_head'](pooled)  # [batch_size, 1]\n",
    "    \n",
    "    return sequence_logits, temp_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4267ff78",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "This seems sumer inefficient IDK\n",
    "\n",
    "so essentially this builds a dictionary of the model including all components.\n",
    "\n",
    "makes n transformer blocks by lopping through\n",
    "'''\n",
    "\n",
    "def create_model_components(vocab_size=21, d_model=256, num_heads=8, num_layers=6, d_ff=1024, dropout=0.1):\n",
    "    components = {\n",
    "        'd_model': d_model,\n",
    "        'amino_acid_embedding': nn.Embedding(vocab_size, d_model),\n",
    "        'temp_embedding': nn.Linear(1, d_model),\n",
    "        'condition_proj': nn.Linear(d_model * 2, d_model),\n",
    "        'output_projection': nn.Linear(d_model, vocab_size),\n",
    "        'temperature_head': nn.Linear(d_model, 1),\n",
    "        'dropout': nn.Dropout(dropout),\n",
    "        'transformer_blocks': []\n",
    "    }\n",
    "    \n",
    "    # Create transformer blocks\n",
    "    for _ in range(num_layers):\n",
    "        block = {\n",
    "            'attention': {\n",
    "                'w_q': nn.Linear(d_model, d_model),\n",
    "                'w_k': nn.Linear(d_model, d_model),\n",
    "                'w_v': nn.Linear(d_model, d_model),\n",
    "                'w_o': nn.Linear(d_model, d_model),\n",
    "                'dropout': nn.Dropout(dropout),\n",
    "                'num_heads': num_heads\n",
    "            },\n",
    "            'norm1': nn.LayerNorm(d_model),\n",
    "            'norm2': nn.LayerNorm(d_model),\n",
    "            'feed_forward': nn.Sequential(\n",
    "                nn.Linear(d_model, d_ff),\n",
    "                nn.ReLU(),\n",
    "                nn.Dropout(dropout),\n",
    "                nn.Linear(d_ff, d_model),\n",
    "                nn.Dropout(dropout)\n",
    "            )\n",
    "        }\n",
    "        components['transformer_blocks'].append(block)\n",
    "    \n",
    "    return components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7b509f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "OK so its in the name\n",
    "\n",
    "beta value is a tensor which schedules the amount of noise added at each time step, it sets early time steps to have little noise and gradually increase it until it gets to 0.02\n",
    "\n",
    "alpha is how much of the signal from the previous timestep is lost in the noise process\n",
    "\n",
    "Alpha bar is how much of the original signal is lost \n",
    "\"\"\"\n",
    "\n",
    "def create_diffusion_schedule(num_timesteps=1000):\n",
    "    betas = torch.linspace(0.0001, 0.02, num_timesteps)\n",
    "    alphas = 1.0 - betas\n",
    "    alpha_bars = torch.cumprod(alphas, dim=0)\n",
    "    return betas, alphas, alpha_bars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62c6b41f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Ok so what this does essentially is get the alpha bar for each appropriate timestep then gets a appropatire string of noise. \n",
    "its then randomly, according to probability determined by the alpha bar mixed the random noise string and the actual protein\n",
    "\"\"\"\n",
    "\n",
    "def add_noise(x_0, t, alpha_bars, vocab_size=21):\n",
    "    batch_size, seq_len = x_0.shape\n",
    "    device = x_0.device\n",
    "    \n",
    "    # Move diffusion schedule to the same device if needed\n",
    "    if alpha_bars.device != device:\n",
    "        alpha_bars = alpha_bars.to(device)\n",
    "    \n",
    "    # Get alpha_bar for each timestep\n",
    "    alpha_bar = alpha_bars[t]  # [batch_size]\n",
    "    \n",
    "    # Sample noise (categorical noise for discrete sequences)\n",
    "    noise = torch.randint(0, vocab_size, (batch_size, seq_len), device=device)\n",
    "    \n",
    "    # Mix original and noise based on alpha_bar\n",
    "    alpha_bar = alpha_bar.unsqueeze(1).expand(-1, seq_len)  # [batch_size, seq_len]\n",
    "    \n",
    "    # Bernoulli sampling: keep original with prob alpha_bar, use noise otherwise\n",
    "    keep_original = torch.bernoulli(alpha_bar).long()\n",
    "    x_t = keep_original * x_0 + (1 - keep_original) * noise\n",
    "    \n",
    "    return x_t, noise\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af46ffa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "gets a random noise timestep\n",
    "\"\"\"\n",
    "\n",
    "def sample_timesteps(batch_size, num_timesteps, device):\n",
    "    return torch.randint(0, num_timesteps, (batch_size,), device=device).long()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac93c626",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Loop through each individual sequence/timestep pair in a batch.\n",
    "\n",
    "convert the sequence into its index token\n",
    "\n",
    "it pads it so its an appropriate length\n",
    "\n",
    "masks its so it is 1 for each real amino acid character 0 for each padding token\n",
    "\n",
    "Accumulate results\n",
    "\"\"\"\n",
    "def create_protein_batch(sequences, temperatures, amino_acid_to_idx, max_len=600):\n",
    "    batch_sequences = []\n",
    "    batch_temperatures = []\n",
    "    batch_masks = []\n",
    "    \n",
    "    for sequence, temperature in zip(sequences, temperatures):\n",
    "        # Convert sequence to indices\n",
    "        seq_indices = [amino_acid_to_idx.get(aa, 0) for aa in sequence]  # 0 for unknown\n",
    "        \n",
    "        # Pad or truncate to max_len\n",
    "        if len(seq_indices) < max_len:\n",
    "            seq_indices.extend([0] * (max_len - len(seq_indices)))  # pad with 0\n",
    "        else:\n",
    "            seq_indices = seq_indices[:max_len]\n",
    "        \n",
    "        # Create attention mask (1 for real tokens, 0 for padding)\n",
    "        mask = [1 if i < len(sequence) else 0 for i in range(max_len)]\n",
    "        \n",
    "        batch_sequences.append(seq_indices)\n",
    "        batch_temperatures.append(temperature)\n",
    "        batch_masks.append(mask)\n",
    "    \n",
    "    return {\n",
    "        'sequence': torch.tensor(batch_sequences, dtype=torch.long),\n",
    "        'temperature': torch.tensor(batch_temperatures, dtype=torch.float32).unsqueeze(-1),\n",
    "        'mask': torch.tensor(batch_masks, dtype=torch.float32)\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "f008c814",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_single_protein(sequence, temperature, amino_acid_to_idx, max_len=600):\n",
    "    # Convert sequence to indices\n",
    "    seq_indices = [amino_acid_to_idx.get(aa, 0) for aa in sequence]  # 0 for unknown\n",
    "    \n",
    "    # Pad or truncate to max_len\n",
    "    if len(seq_indices) < max_len:\n",
    "        seq_indices.extend([0] * (max_len - len(seq_indices)))  # pad with 0\n",
    "    else:\n",
    "        seq_indices = seq_indices[:max_len]\n",
    "    \n",
    "    # Create attention mask (1 for real tokens, 0 for padding)\n",
    "    mask = [1 if i < len(sequence) else 0 for i in range(max_len)]\n",
    "    \n",
    "    return {\n",
    "        'sequence': torch.tensor(seq_indices, dtype=torch.long),\n",
    "        'temperature': torch.tensor([temperature], dtype=torch.float32),\n",
    "        'mask': torch.tensor(mask, dtype=torch.float32)\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a58b83f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This essentially makes two seperate dictionaries\n",
    "# aa_to_idx maps the values of the amino acids to its index - encoding\n",
    "# idx_to_aa maps the values of the index to its amino acids - decoding\n",
    "\n",
    "\n",
    "def create_amino_acid_vocab():\n",
    "    amino_acids = ['PAD', 'A', 'R', 'N', 'D', 'C', 'Q', 'E', 'G', 'H', 'I', \n",
    "                   'L', 'K', 'M', 'F', 'P', 'S', 'T', 'W', 'Y', 'V']\n",
    "    aa_to_idx = {aa: idx for idx, aa in enumerate(amino_acids)}\n",
    "    idx_to_aa = {idx: aa for idx, aa in enumerate(amino_acids)}\n",
    "    return aa_to_idx, idx_to_aa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35e86dd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Simply loads the data from csv puts in in panda. Locates the sequence data and temp data. ensures that we have good data points. \n",
    "\n",
    "Exception  needs to be straight up removed. There is no need for dummy data\n",
    "\"\"\"\n",
    "\n",
    "def load_protein_data(csv_path: str) -> Tuple[List[str], List[float]]:\n",
    "    try:\n",
    "        df = pd.read_csv(csv_path)\n",
    "        print(f\"Loaded data with columns: {df.columns.tolist()}\")\n",
    "        print(f\"Data shape: {df.shape}\")\n",
    "        \n",
    "        # Try to identify sequence and temperature columns\n",
    "        sequence_col = None\n",
    "        temp_col = None\n",
    "        \n",
    "        for col in df.columns:\n",
    "            if 'seq' in col.lower():\n",
    "                sequence_col = col\n",
    "            elif any(temp_name in col.lower() for temp_name in ['temp', 'tm', 'melt']):\n",
    "                temp_col = col\n",
    "        \n",
    "        if sequence_col is None:\n",
    "            print(\"Available columns:\", df.columns.tolist())\n",
    "            raise ValueError(\"Could not find sequence column. Please ensure column name contains 'seq'\")\n",
    "        \n",
    "        if temp_col is None:\n",
    "            print(\"Available columns:\", df.columns.tolist())\n",
    "            raise ValueError(\"Could not find temperature column. Please ensure column name contains 'temp', 'tm', or 'melt'\")\n",
    "        \n",
    "        # Clean the data\n",
    "        df = df.dropna(subset=[sequence_col, temp_col])\n",
    "        \n",
    "        sequences = df[sequence_col].tolist()\n",
    "        temperatures = df[temp_col].tolist()\n",
    "        \n",
    "        # Filter out sequences that are too short or too long\n",
    "        filtered_sequences = []\n",
    "        filtered_temperatures = []\n",
    "        \n",
    "        for seq, temp in zip(sequences, temperatures):\n",
    "            if isinstance(seq, str) and 50 <= len(seq) <= 600:  # reasonable protein length\n",
    "                # Clean sequence (remove non-amino acid characters)\n",
    "                cleaned_seq = ''.join([c for c in seq.upper() if c in 'ARNDCQEGHILKMFPSTWYV'])\n",
    "                if len(cleaned_seq) >= 50:\n",
    "                    filtered_sequences.append(cleaned_seq)\n",
    "                    filtered_temperatures.append(float(temp))\n",
    "        \n",
    "        print(f\"Filtered to {len(filtered_sequences)} valid sequences\")\n",
    "        return filtered_sequences, filtered_temperatures\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error loading data: {e}\")\n",
    "        # Return dummy data for testing\n",
    "        print(\"Using dummy data for testing...\")\n",
    "        dummy_sequences = [\n",
    "            'MVKKTFVSLVAAASCLAGVSVAAAVATAAADAPAAGTAADAAADLASAEAGLVPQGAAHVAGAATVAGTVVAASAALAADADAGAAEVAGAEAVVVAGAADSAAQSTVAAAAEAVVAGAAGAAGAGTVGSETVAGAAAGAAAGAETVEQAADMGTVVTASGTAGAAAAAEAGAAGAATGAAGGTGAAGAAGAAGAAGAAGAGAGAGA',\n",
    "            'MAAKLVFSLVAAAFCLAGVSVAAAVATAAADAPAAGTAADAAADLASAEAGLVPQGAAHVAGAATVAGTVVAASAALAADADAGAAEVAGAEAVVVAGAADSAAQSTVAAAAEAVVAGAAGAAGAGTVGSETVAGAAAGAAAGAETVEQAADMGTVVTASGTAGAAAAAEAGAAGAATGAAGGTGAAGAAGAAGAAGAAGAGAGA',\n",
    "            'MAKKLVFSLVAAAFCLAGVSVAAAVATAAADAPAAGTAADAAADLASAEAGLVPQGAAHVAGAATVAGTVVAASAALAADADAGAAEVAGAEAVVVAGAADSAAQSTVAAAAEAVVAGAAGAAGAGTVGSETVAGAAAGAAAGAETVEQAADMGTVVTASGTAGAAAAAEAGAAGAATGAAGGTGAAGAAGAAGAAGAAGAGAGA'\n",
    "        ]\n",
    "        dummy_temperatures = [55.0, 65.0, 75.0]\n",
    "        return dummy_sequences, dummy_temperatures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "015b0820",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "\"\"\"\n",
    "\n",
    "def train_diffusion_model(model_components, train_data, val_data, \n",
    "                         diffusion_schedule, num_epochs=100, \n",
    "                         learning_rate=1e-4, device=torch.device('cpu')):\n",
    "\n",
    "    for key, component in model_components.items():\n",
    "        if isinstance(component, (nn.Module, torch.Tensor)):\n",
    "            if hasattr(component, 'to'):\n",
    "                model_components[key] = component.to(device)\n",
    "        elif isinstance(component, list):  # transformer blocks\n",
    "            for block in component:\n",
    "                for block_key, block_component in block.items():\n",
    "                    if isinstance(block_component, dict):  # attention dict\n",
    "                        for att_key, att_component in block_component.items():\n",
    "                            if hasattr(att_component, 'to'):\n",
    "                                block_component[att_key] = att_component.to(device)\n",
    "                    elif hasattr(block_component, 'to'):\n",
    "                        block[block_key] = block_component.to(device)\n",
    "    \n",
    "    # Get all parameters for optimizer\n",
    "    all_params = []\n",
    "    def collect_params(component):\n",
    "        if hasattr(component, 'parameters'):\n",
    "            all_params.extend(component.parameters())\n",
    "        elif isinstance(component, dict):\n",
    "            for v in component.values():\n",
    "                collect_params(v)\n",
    "        elif isinstance(component, list):\n",
    "            for item in component:\n",
    "                collect_params(item)\n",
    "    \n",
    "    collect_params(model_components)\n",
    "    \n",
    "    optimizer = optim.AdamW(all_params, lr=learning_rate, weight_decay=1e-4)\n",
    "    scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=num_epochs)\n",
    "    \n",
    "    betas, alphas, alpha_bars = diffusion_schedule\n",
    "    alpha_bars = alpha_bars.to(device)\n",
    "    \n",
    "    train_losses = []\n",
    "    val_losses = []\n",
    "    \n",
    "    print(\"Starting training...\")\n",
    "    \n",
    "    # Fix: Use the actual number of sequences\n",
    "    num_train_sequences = len(train_data['sequences'])\n",
    "    num_val_sequences = len(val_data['sequences'])\n",
    "    batch_size = 8\n",
    "    \n",
    "    print(f\"Training sequences: {num_train_sequences}\")\n",
    "    print(f\"Validation sequences: {num_val_sequences}\")\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        # Training phase\n",
    "        for component in model_components.values():\n",
    "            if hasattr(component, 'train'):\n",
    "                component.train()\n",
    "        \n",
    "        train_loss = 0.0\n",
    "        num_batches = max(1, num_train_sequences // batch_size)  # Ensure at least 1 batch\n",
    "        \n",
    "        for batch_idx in range(num_batches):\n",
    "            # Get batch\n",
    "            start_idx = batch_idx * batch_size\n",
    "            end_idx = min(start_idx + batch_size, num_train_sequences)\n",
    "            \n",
    "            batch_sequences = train_data['sequences'][start_idx:end_idx]\n",
    "            batch_temps = train_data['temperatures'][start_idx:end_idx]\n",
    "            \n",
    "            # Skip if batch is empty\n",
    "            if len(batch_sequences) == 0:\n",
    "                continue\n",
    "            \n",
    "            # Process batch\n",
    "            batch = create_protein_batch(batch_sequences, batch_temps, \n",
    "                                       train_data['amino_acid_to_idx'])\n",
    "            \n",
    "            sequences = batch['sequence'].to(device)\n",
    "            temperatures = batch['temperature'].to(device)\n",
    "            masks = batch['mask'].to(device)\n",
    "            \n",
    "            actual_batch_size = sequences.shape[0]\n",
    "            \n",
    "            # Sample timesteps and add noise\n",
    "            timesteps = sample_timesteps(actual_batch_size, 1000, device)\n",
    "            noisy_sequences, _ = add_noise(sequences, timesteps, alpha_bars)\n",
    "            \n",
    "            # Forward pass\n",
    "            pred_logits, pred_temp = rubisco_diffusion_forward(\n",
    "                noisy_sequences, timesteps, temperatures, model_components, masks)\n",
    "            \n",
    "            # Calculate loss - Fix: use vocab_size (21) instead of d_model\n",
    "            seq_loss = F.cross_entropy(\n",
    "                pred_logits.view(-1, 21),  # vocab_size = 21\n",
    "                sequences.view(-1),\n",
    "                reduction='none'\n",
    "            )\n",
    "            seq_loss = seq_loss.view(actual_batch_size, -1) * masks\n",
    "            seq_loss = seq_loss.sum() / masks.sum()\n",
    "            \n",
    "            temp_loss = F.mse_loss(pred_temp, temperatures)\n",
    "            total_loss = seq_loss + 0.1 * temp_loss\n",
    "            \n",
    "            # Backward pass\n",
    "            optimizer.zero_grad()\n",
    "            total_loss.backward()\n",
    "            torch.nn.utils.clip_grad_norm_(all_params, max_norm=1.0)\n",
    "            optimizer.step()\n",
    "            \n",
    "            train_loss += total_loss.item()\n",
    "            \n",
    "            if batch_idx % 10 == 0:\n",
    "                print(f'Epoch {epoch}, Batch {batch_idx}: Loss = {total_loss.item():.4f}')\n",
    "        \n",
    "        # Validation phase\n",
    "        for component in model_components.values():\n",
    "            if hasattr(component, 'eval'):\n",
    "                component.eval()\n",
    "        \n",
    "        val_loss = 0.0\n",
    "        val_batches = max(1, num_val_sequences // batch_size)  # Ensure at least 1 batch\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for batch_idx in range(val_batches):\n",
    "                start_idx = batch_idx * batch_size\n",
    "                end_idx = min(start_idx + batch_size, num_val_sequences)\n",
    "                \n",
    "                batch_sequences = val_data['sequences'][start_idx:end_idx]\n",
    "                batch_temps = val_data['temperatures'][start_idx:end_idx]\n",
    "                \n",
    "                # Skip if batch is empty\n",
    "                if len(batch_sequences) == 0:\n",
    "                    continue\n",
    "                \n",
    "                batch = create_protein_batch(batch_sequences, batch_temps,\n",
    "                                           val_data['amino_acid_to_idx'])\n",
    "                \n",
    "                sequences = batch['sequence'].to(device)\n",
    "                temperatures = batch['temperature'].to(device)\n",
    "                masks = batch['mask'].to(device)\n",
    "                \n",
    "                actual_batch_size = sequences.shape[0]\n",
    "                timesteps = sample_timesteps(actual_batch_size, 1000, device)\n",
    "                noisy_sequences, _ = add_noise(sequences, timesteps, alpha_bars)\n",
    "                \n",
    "                pred_logits, pred_temp = rubisco_diffusion_forward(\n",
    "                    noisy_sequences, timesteps, temperatures, model_components, masks)\n",
    "                \n",
    "                seq_loss = F.cross_entropy(\n",
    "                    pred_logits.view(-1, 21),  # vocab_size = 21\n",
    "                    sequences.view(-1),\n",
    "                    reduction='none'\n",
    "                )\n",
    "                seq_loss = seq_loss.view(actual_batch_size, -1) * masks\n",
    "                seq_loss = seq_loss.sum() / masks.sum()\n",
    "                \n",
    "                temp_loss = F.mse_loss(pred_temp, temperatures)\n",
    "                total_loss = seq_loss + 0.1 * temp_loss\n",
    "                \n",
    "                val_loss += total_loss.item()\n",
    "        \n",
    "        train_loss /= num_batches\n",
    "        val_loss /= val_batches\n",
    "        \n",
    "        train_losses.append(train_loss)\n",
    "        val_losses.append(val_loss)\n",
    "        \n",
    "        scheduler.step()\n",
    "        \n",
    "        print(f'Epoch {epoch+1}/{num_epochs}: '\n",
    "              f'Train Loss = {train_loss:.4f}, Val Loss = {val_loss:.4f}')\n",
    "    \n",
    "    return train_losses, val_losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "58d5f6a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_sequences(model_components, diffusion_schedule, target_temperatures,\n",
    "                      sequence_length=300, num_samples=5, device=torch.device('cpu'),\n",
    "                      idx_to_aa=None):\n",
    "    \"\"\"\n",
    "    Generate protein sequences using simplified diffusion model\n",
    "    \"\"\"\n",
    "    betas, alphas, alpha_bars = diffusion_schedule\n",
    "    num_timesteps = len(betas)\n",
    "    vocab_size = 21\n",
    "    \n",
    "    # Set all components to eval mode\n",
    "    for component in model_components.values():\n",
    "        if hasattr(component, 'eval'):\n",
    "            component.eval()\n",
    "    \n",
    "    generated_sequences = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for target_temp in target_temperatures:\n",
    "            for _ in range(num_samples):\n",
    "                # Start with random noise\n",
    "                x = torch.randint(1, vocab_size, (1, sequence_length), device=device)\n",
    "                target_temp_tensor = torch.tensor([[target_temp]], device=device, dtype=torch.float32)\n",
    "                \n",
    "                # Reverse diffusion process\n",
    "                for t in reversed(range(num_timesteps)):\n",
    "                    timestep = torch.tensor([t], device=device, dtype=torch.long)\n",
    "                    \n",
    "                    # Predict clean sequence\n",
    "                    pred_logits, _ = rubisco_diffusion_forward(\n",
    "                        x, timestep, target_temp_tensor, model_components)\n",
    "                    \n",
    "                    # Sample from predicted distribution\n",
    "                    probs = F.softmax(pred_logits, dim=-1)\n",
    "                    x = torch.multinomial(probs.view(-1, vocab_size), 1).view(1, -1)\n",
    "                \n",
    "                # Convert to amino acid sequence\n",
    "                if idx_to_aa is not None:\n",
    "                    sequence = ''.join([idx_to_aa[idx.item()] for idx in x[0] if idx.item() != 0])\n",
    "                    generated_sequences.append(sequence)\n",
    "                else:\n",
    "                    generated_sequences.append(x[0].cpu().numpy())\n",
    "    \n",
    "    return generated_sequences\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "bd1890f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_single_sequence(model_components, diffusion_schedule, target_temp,\n",
    "                           sequence_length=300, device=torch.device('cpu'),\n",
    "                           idx_to_aa=None):\n",
    "    \"\"\"Generate a single protein sequence\"\"\"\n",
    "    betas, alphas, alpha_bars = diffusion_schedule\n",
    "    num_timesteps = len(betas)\n",
    "    vocab_size = 21\n",
    "    \n",
    "    # Set all components to eval mode\n",
    "    for component in model_components.values():\n",
    "        if hasattr(component, 'eval'):\n",
    "            component.eval()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        # Start with random noise\n",
    "        x = torch.randint(1, vocab_size, (1, sequence_length), device=device)\n",
    "        target_temp_tensor = torch.tensor([[target_temp]], device=device, dtype=torch.float32)\n",
    "        \n",
    "        # Reverse diffusion process\n",
    "        for t in reversed(range(num_timesteps)):\n",
    "            timestep = torch.tensor([t], device=device, dtype=torch.long)\n",
    "            \n",
    "            # Predict clean sequence\n",
    "            pred_logits, _ = rubisco_diffusion_forward(\n",
    "                x, timestep, target_temp_tensor, model_components)\n",
    "            \n",
    "            # Sample from predicted distribution\n",
    "            probs = F.softmax(pred_logits, dim=-1)\n",
    "            x = torch.multinomial(probs.view(-1, vocab_size), 1).view(1, -1)\n",
    "        \n",
    "        # Convert to amino acid sequence\n",
    "        if idx_to_aa is not None:\n",
    "            sequence = ''.join([idx_to_aa[idx.item()] for idx in x[0] if idx.item() != 0])\n",
    "            return sequence\n",
    "        else:\n",
    "            return x[0].cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "acdbb954",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_training_curves(train_losses, val_losses, save_path=None):\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(train_losses, label='Training Loss', color='blue', linewidth=2)\n",
    "    plt.plot(val_losses, label='Validation Loss', color='red', linewidth=2)\n",
    "    plt.xlabel('Epoch', fontsize=12)\n",
    "    plt.ylabel('Loss', fontsize=12)\n",
    "    plt.title('Training and Validation Loss', fontsize=14)\n",
    "    plt.legend(fontsize=12)\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    \n",
    "    if save_path:\n",
    "        plt.savefig(save_path, dpi=300, bbox_inches='tight')\n",
    "        print(f\"Plot saved to {save_path}\")\n",
    "    \n",
    "    plt.show()\n",
    "\n",
    "def quick_plot(losses, title=\"Loss\"):\n",
    "    plt.figure(figsize=(8, 5))\n",
    "    plt.plot(losses, color='blue', linewidth=2)\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.title(title)\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "022a194e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "Loaded data with columns: ['Entry', 'Protein names', 'Gene Names', 'Organism', 'Length', 'EC number', 'Gene Ontology (GO)', 'Keywords', 'Sequence', 'UNIPROT_ID', 'Tm_(C)']\n",
      "Data shape: (275, 11)\n",
      "Filtered to 243 valid sequences\n",
      "Model has 4881430 parameters\n",
      "Starting training...\n",
      "Starting training...\n",
      "Training sequences: 194\n",
      "Validation sequences: 49\n",
      "Starting training...\n",
      "Training sequences: 194\n",
      "Validation sequences: 49\n",
      "Epoch 0, Batch 0: Loss = 622.5971\n",
      "Epoch 0, Batch 0: Loss = 622.5971\n",
      "Epoch 0, Batch 10: Loss = 550.7206\n",
      "Epoch 0, Batch 10: Loss = 550.7206\n",
      "Epoch 0, Batch 20: Loss = 434.0396\n",
      "Epoch 0, Batch 20: Loss = 434.0396\n",
      "Epoch 1/50: Train Loss = 519.2177, Val Loss = 504.6666\n",
      "Epoch 1, Batch 0: Loss = 482.7177\n",
      "Epoch 1/50: Train Loss = 519.2177, Val Loss = 504.6666\n",
      "Epoch 1, Batch 0: Loss = 482.7177\n",
      "Epoch 1, Batch 10: Loss = 538.2560\n",
      "Epoch 1, Batch 10: Loss = 538.2560\n",
      "Epoch 1, Batch 20: Loss = 424.8104\n",
      "Epoch 1, Batch 20: Loss = 424.8104\n",
      "Epoch 2/50: Train Loss = 492.2733, Val Loss = 495.2012\n",
      "Epoch 2, Batch 0: Loss = 473.4638\n",
      "Epoch 2/50: Train Loss = 492.2733, Val Loss = 495.2012\n",
      "Epoch 2, Batch 0: Loss = 473.4638\n",
      "Epoch 2, Batch 10: Loss = 528.8478\n",
      "Epoch 2, Batch 20: Loss = 416.4703\n",
      "Epoch 3/50: Train Loss = 483.2735, Val Loss = 486.2449\n",
      "Epoch 3, Batch 0: Loss = 464.7034\n",
      "Epoch 3, Batch 10: Loss = 519.5405\n",
      "Epoch 3, Batch 20: Loss = 408.1938\n",
      "Epoch 4/50: Train Loss = 474.4144, Val Loss = 477.3189\n",
      "Epoch 4, Batch 0: Loss = 455.9835\n",
      "Epoch 4, Batch 10: Loss = 510.2289\n",
      "Epoch 4, Batch 20: Loss = 399.9192\n",
      "Epoch 5/50: Train Loss = 465.5656, Val Loss = 468.3903\n",
      "Epoch 5, Batch 0: Loss = 447.2643\n",
      "Epoch 5, Batch 10: Loss = 500.9157\n",
      "Epoch 5, Batch 20: Loss = 391.6534\n",
      "Epoch 6/50: Train Loss = 456.7154, Val Loss = 459.4598\n",
      "Epoch 6, Batch 0: Loss = 438.5461\n",
      "Epoch 6, Batch 10: Loss = 491.5992\n",
      "Epoch 6, Batch 20: Loss = 383.3999\n",
      "Epoch 7/50: Train Loss = 447.8682, Val Loss = 450.5371\n",
      "Epoch 7, Batch 0: Loss = 429.8358\n",
      "Epoch 7, Batch 10: Loss = 482.2939\n",
      "Epoch 7, Batch 20: Loss = 375.1696\n",
      "Epoch 8/50: Train Loss = 439.0374, Val Loss = 441.6395\n",
      "Epoch 8, Batch 0: Loss = 421.1518\n",
      "Epoch 8, Batch 10: Loss = 473.0217\n",
      "Epoch 8, Batch 20: Loss = 366.9910\n",
      "Epoch 9/50: Train Loss = 430.2429, Val Loss = 432.7918\n",
      "Epoch 9, Batch 0: Loss = 412.5181\n",
      "Epoch 9, Batch 10: Loss = 463.8096\n",
      "Epoch 9, Batch 20: Loss = 358.8857\n",
      "Epoch 10/50: Train Loss = 421.5123, Val Loss = 424.0231\n",
      "Epoch 10, Batch 0: Loss = 403.9650\n",
      "Epoch 10, Batch 10: Loss = 454.6879\n",
      "Epoch 10, Batch 20: Loss = 350.8888\n",
      "Epoch 11/50: Train Loss = 412.8772, Val Loss = 415.3679\n",
      "Epoch 11, Batch 0: Loss = 395.5231\n",
      "Epoch 11, Batch 10: Loss = 445.6954\n",
      "Epoch 11, Batch 20: Loss = 343.0261\n",
      "Epoch 12/50: Train Loss = 404.3698, Val Loss = 406.8568\n",
      "Epoch 12, Batch 0: Loss = 387.2253\n",
      "Epoch 12, Batch 10: Loss = 436.8641\n",
      "Epoch 12, Batch 20: Loss = 335.3283\n",
      "Epoch 13/50: Train Loss = 396.0207, Val Loss = 398.5199\n",
      "Epoch 13, Batch 0: Loss = 379.0979\n",
      "Epoch 13, Batch 10: Loss = 428.2206\n",
      "Epoch 13, Batch 20: Loss = 327.8154\n",
      "Epoch 14/50: Train Loss = 387.8571, Val Loss = 390.3826\n",
      "Epoch 14, Batch 0: Loss = 371.1691\n",
      "Epoch 14, Batch 10: Loss = 419.7946\n",
      "Epoch 14, Batch 20: Loss = 320.5113\n",
      "Epoch 15/50: Train Loss = 379.9038, Val Loss = 382.4687\n",
      "Epoch 15, Batch 0: Loss = 363.4601\n",
      "Epoch 15, Batch 10: Loss = 411.6060\n",
      "Epoch 15, Batch 20: Loss = 313.4351\n",
      "Epoch 16/50: Train Loss = 372.1818, Val Loss = 374.7978\n",
      "Epoch 16, Batch 0: Loss = 355.9886\n",
      "Epoch 16, Batch 10: Loss = 403.6757\n",
      "Epoch 16, Batch 20: Loss = 306.6005\n",
      "Epoch 17/50: Train Loss = 364.7093, Val Loss = 367.3882\n",
      "Epoch 17, Batch 0: Loss = 348.7729\n",
      "Epoch 17, Batch 10: Loss = 396.0237\n",
      "Epoch 17, Batch 20: Loss = 300.0254\n",
      "Epoch 18/50: Train Loss = 357.5036, Val Loss = 360.2534\n",
      "Epoch 18, Batch 0: Loss = 341.8288\n",
      "Epoch 18, Batch 10: Loss = 388.6621\n",
      "Epoch 18, Batch 20: Loss = 293.7142\n",
      "Epoch 19/50: Train Loss = 350.5772, Val Loss = 353.4069\n",
      "Epoch 19, Batch 0: Loss = 335.1662\n",
      "Epoch 19, Batch 10: Loss = 381.6028\n",
      "Epoch 19, Batch 20: Loss = 287.6820\n",
      "Epoch 20/50: Train Loss = 343.9411, Val Loss = 346.8584\n",
      "Epoch 20, Batch 0: Loss = 328.7953\n",
      "Epoch 20, Batch 10: Loss = 374.8579\n",
      "Epoch 20, Batch 20: Loss = 281.9332\n",
      "Epoch 21/50: Train Loss = 337.6046, Val Loss = 340.6150\n",
      "Epoch 21, Batch 0: Loss = 322.7240\n",
      "Epoch 21, Batch 10: Loss = 368.4332\n",
      "Epoch 21, Batch 20: Loss = 276.4708\n",
      "Epoch 22/50: Train Loss = 331.5734, Val Loss = 334.6836\n",
      "Epoch 22, Batch 0: Loss = 316.9562\n",
      "Epoch 22, Batch 10: Loss = 362.3342\n",
      "Epoch 22, Batch 20: Loss = 271.3017\n",
      "Epoch 23/50: Train Loss = 325.8530, Val Loss = 329.0663\n",
      "Epoch 23, Batch 0: Loss = 311.4940\n",
      "Epoch 23, Batch 10: Loss = 356.5663\n",
      "Epoch 23, Batch 20: Loss = 266.4256\n",
      "Epoch 24/50: Train Loss = 320.4454, Val Loss = 323.7660\n",
      "Epoch 24, Batch 0: Loss = 306.3408\n",
      "Epoch 24, Batch 10: Loss = 351.1278\n",
      "Epoch 24, Batch 20: Loss = 261.8390\n",
      "Epoch 25/50: Train Loss = 315.3515, Val Loss = 318.7822\n",
      "Epoch 25, Batch 0: Loss = 301.5016\n",
      "Epoch 25, Batch 10: Loss = 346.0211\n",
      "Epoch 25, Batch 20: Loss = 257.5468\n",
      "Epoch 26/50: Train Loss = 310.5713, Val Loss = 314.1147\n",
      "Epoch 26, Batch 0: Loss = 296.9665\n",
      "Epoch 26, Batch 10: Loss = 341.2428\n",
      "Epoch 26, Batch 20: Loss = 253.5406\n",
      "Epoch 27/50: Train Loss = 306.1026, Val Loss = 309.7601\n",
      "Epoch 27, Batch 0: Loss = 292.7380\n",
      "Epoch 27, Batch 10: Loss = 336.7910\n",
      "Epoch 27, Batch 20: Loss = 249.8192\n",
      "Epoch 28/50: Train Loss = 301.9413, Val Loss = 305.7141\n",
      "Epoch 28, Batch 0: Loss = 288.8083\n",
      "Epoch 28, Batch 10: Loss = 332.6619\n",
      "Epoch 28, Batch 20: Loss = 246.3756\n",
      "Epoch 29/50: Train Loss = 298.0841, Val Loss = 301.9720\n",
      "Epoch 29, Batch 0: Loss = 285.1766\n",
      "Epoch 29, Batch 10: Loss = 328.8458\n",
      "Epoch 29, Batch 20: Loss = 243.2055\n",
      "Epoch 30/50: Train Loss = 294.5245, Val Loss = 298.5269\n",
      "Epoch 30, Batch 0: Loss = 281.8329\n",
      "Epoch 30, Batch 10: Loss = 325.3429\n",
      "Epoch 30, Batch 20: Loss = 240.3036\n",
      "Epoch 31/50: Train Loss = 291.2559, Val Loss = 295.3724\n",
      "Epoch 31, Batch 0: Loss = 278.7697\n",
      "Epoch 31, Batch 10: Loss = 322.1393\n",
      "Epoch 31, Batch 20: Loss = 237.6578\n",
      "Epoch 32/50: Train Loss = 288.2700, Val Loss = 292.5001\n",
      "Epoch 32, Batch 0: Loss = 275.9823\n",
      "Epoch 32, Batch 10: Loss = 319.2289\n",
      "Epoch 32, Batch 20: Loss = 235.2631\n",
      "Epoch 33/50: Train Loss = 285.5586, Val Loss = 289.8997\n",
      "Epoch 33, Batch 0: Loss = 273.4599\n",
      "Epoch 33, Batch 10: Loss = 316.5993\n",
      "Epoch 33, Batch 20: Loss = 233.1060\n",
      "Epoch 34/50: Train Loss = 283.1121, Val Loss = 287.5606\n",
      "Epoch 34, Batch 0: Loss = 271.1917\n",
      "Epoch 34, Batch 10: Loss = 314.2422\n",
      "Epoch 34, Batch 20: Loss = 231.1792\n",
      "Epoch 35/50: Train Loss = 280.9199, Val Loss = 285.4740\n",
      "Epoch 35, Batch 0: Loss = 269.1662\n",
      "Epoch 35, Batch 10: Loss = 312.1450\n",
      "Epoch 35, Batch 20: Loss = 229.4741\n",
      "Epoch 36/50: Train Loss = 278.9707, Val Loss = 283.6282\n",
      "Epoch 36, Batch 0: Loss = 267.3752\n",
      "Epoch 36, Batch 10: Loss = 310.2951\n",
      "Epoch 36, Batch 20: Loss = 227.9746\n",
      "Epoch 37/50: Train Loss = 277.2531, Val Loss = 282.0092\n",
      "Epoch 37, Batch 0: Loss = 265.8065\n",
      "Epoch 37, Batch 10: Loss = 308.6799\n",
      "Epoch 37, Batch 20: Loss = 226.6737\n",
      "Epoch 38/50: Train Loss = 275.7543, Val Loss = 280.6043\n",
      "Epoch 38, Batch 0: Loss = 264.4473\n",
      "Epoch 38, Batch 10: Loss = 307.2848\n",
      "Epoch 38, Batch 20: Loss = 225.5557\n",
      "Epoch 39/50: Train Loss = 274.4618, Val Loss = 279.4012\n",
      "Epoch 39, Batch 0: Loss = 263.2783\n",
      "Epoch 39, Batch 10: Loss = 306.0952\n",
      "Epoch 39, Batch 20: Loss = 224.6094\n",
      "Epoch 40/50: Train Loss = 273.3608, Val Loss = 278.3852\n",
      "Epoch 40, Batch 0: Loss = 262.2937\n",
      "Epoch 40, Batch 10: Loss = 305.0994\n",
      "Epoch 40, Batch 20: Loss = 223.8209\n",
      "Epoch 41/50: Train Loss = 272.4385, Val Loss = 277.5415\n",
      "Epoch 41, Batch 0: Loss = 261.4769\n",
      "Epoch 41, Batch 10: Loss = 304.2747\n",
      "Epoch 41, Batch 20: Loss = 223.1804\n",
      "Epoch 42/50: Train Loss = 271.6794, Val Loss = 276.8553\n",
      "Epoch 42, Batch 0: Loss = 260.8112\n",
      "Epoch 42, Batch 10: Loss = 303.6160\n",
      "Epoch 42, Batch 20: Loss = 222.6652\n",
      "Epoch 43/50: Train Loss = 271.0687, Val Loss = 276.3117\n",
      "Epoch 43, Batch 0: Loss = 260.2841\n",
      "Epoch 43, Batch 10: Loss = 303.0946\n",
      "Epoch 43, Batch 20: Loss = 222.2714\n",
      "Epoch 44/50: Train Loss = 270.5908, Val Loss = 275.8937\n",
      "Epoch 44, Batch 0: Loss = 259.8813\n",
      "Epoch 44, Batch 10: Loss = 302.7030\n",
      "Epoch 44, Batch 20: Loss = 221.9757\n",
      "Epoch 45/50: Train Loss = 270.2305, Val Loss = 275.5870\n",
      "Epoch 45, Batch 0: Loss = 259.5811\n",
      "Epoch 45, Batch 10: Loss = 302.4193\n",
      "Epoch 45, Batch 20: Loss = 221.7681\n",
      "Epoch 46/50: Train Loss = 269.9704, Val Loss = 275.3724\n",
      "Epoch 46, Batch 0: Loss = 259.3723\n",
      "Epoch 46, Batch 10: Loss = 302.2259\n",
      "Epoch 46, Batch 20: Loss = 221.6342\n",
      "Epoch 47/50: Train Loss = 269.7953, Val Loss = 275.2346\n",
      "Epoch 47, Batch 0: Loss = 259.2404\n",
      "Epoch 47, Batch 10: Loss = 302.1085\n",
      "Epoch 47, Batch 20: Loss = 221.5540\n",
      "Epoch 48/50: Train Loss = 269.6883, Val Loss = 275.1573\n",
      "Epoch 48, Batch 0: Loss = 259.1636\n",
      "Epoch 48, Batch 10: Loss = 302.0441\n",
      "Epoch 48, Batch 20: Loss = 221.5175\n",
      "Epoch 49/50: Train Loss = 269.6316, Val Loss = 275.1233\n",
      "Epoch 49, Batch 0: Loss = 259.1333\n",
      "Epoch 49, Batch 10: Loss = 302.0212\n",
      "Epoch 49, Batch 20: Loss = 221.5066\n",
      "Epoch 50/50: Train Loss = 269.6105, Val Loss = 275.1150\n",
      "Plot saved to training_curves.png\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA1YAAAIoCAYAAABqA3puAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjMsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvZiW1igAAAAlwSFlzAAAPYQAAD2EBqD+naQAAjjFJREFUeJzt3Qd4U9X/x/FP2XtvQURRERVBhqKykSEgAvpHmeJGHIA4UHDgAEUFcSGoTBEFGYLsDQoi4h78xAEqIAiyN83/+d5DmrS00DYtSdr363mu6b25SU7TS82n55zvifH5fD4BAAAAAFItS+ofCgAAAAAwBCsAAAAACBHBCgAAAABCRLACAAAAgBARrAAAAAAgRAQrAAAAAAgRwQoAAAAAQkSwAgAAAIAQEawAAAAAIEQEKwAIk5iYGNWvXz+k51iyZIn3PE8++WSatSua2ftp70ckGD16tNcWuw121llneVuoz5OW7Pqx17DrCQCQOgQrAJmafZhMyYaMoUOHDt7P8/333z/pebt371aePHlUqFAhHThwQNEq2gK4P+hNnDgx3E0BgGTLlvxTASDjeeKJJ044NnToUO3atSvR+9LSTz/95H1oD0WtWrW85ylWrFiatSszuPXWW71Q9e677+qmm25K8jw7xwJV165dlTt37jR57YULFyrS3HPPPbrxxht15plnhrspABC1CFYAMrXE/oJvQ64sWKX3X/crVaoU8nNYMEuL58lsGjZsqAoVKmjRokXauHFjkoHCgpc/iKWVc845R5HGgjnhHABCw1BAAEiGP/74wxuadPPNN3s9RG3atFHRokW9Y3afmTp1qtf7UbFiRS/wFCxYUHXq1NFHH32U7DlW9vx2/Pfff9ewYcO80JQzZ06VL19eTz31lGJjY5M1xMs/j2fv3r26//77VaZMGe95qlSposmTJyf5PbZv315FihRRvnz5VK9ePS1btizF829S8j4Ev6/r16/33tfChQsrb968aty4sb755ptEX2PFihVe++w8+zlYu//8808ll71mt27dvPdz1KhRiZ7zww8/aPXq1d57VqNGDS9sP//8897r2vuZI0cO77ZLly769ddfk/3aSc2x2rFjh+666y6VLFnSe99q1qzpvZdJsdDXunVr77ly5crl/dyaNm2qxYsXxzvPfn4NGjTwvrZrKHhoq//aPdnPeMaMGd7j7edovXaXXHKJXn75ZR09ejRNfpZpIbltNPb+NG/ePO7fhL3fdn2OGDEi3nlr167V9ddf74VuO6948eLez+TZZ59Nt+8DQHSjxwoAUsA+MF5++eW6+OKLvQ+Q27dv9z5gm759+3pfX3XVVSpdurS2bdumjz/+2PtwZiHp3nvvTfbrPPjgg1q6dKlatmzpfVieNm2a9+H38OHDyf5gd+TIETVp0kT//fef2rVrp/3793tzVv7v//5Pc+bM8e7z+/vvv3XFFVdo8+bNatasmapVq6Z169bp6quv9np3UiI174N9KLf39cILL9Qtt9ziBZXp06d7H5YtyNqH3+ChdPbBOEuWLF6gsg/IduzKK6/0Psgnl/387D21HsrHH3/8hDl0/sDl762ydth51iYLDRYYfv75Z02YMEGffPKJ90HcAnBq2M/GQvZ3332n2rVre+HNgqJ9f8E/p2A9evTwAoSFFvvQbz9Du05sf8qUKV7oMva89v6OGTPGe97gMG9zx07GwskDDzzghTabl2bfs/0s7djy5cu910n4vqXkZ5kWUtJG+zm1atXK+77t/fFfnxb6xo0bpzvuuMM77+uvv/b+PWTNmtU7z36uO3fu1I8//ugFsMceeyxNvwcAGYQPABBP+fLlfQl/Pf7+++/eMdsef/zxRB/366+/nnBsz549vosvvthXsGBB3759++LdZ89Vr169eMe6du3qHa9QoYJv06ZNcce3bdvmK1SokC9//vy+Q4cOxR1fvHixd/4TTzyR6PfQunXreOcvWLDAO960adN453fq1Mk7/uyzz8Y7/s4778R93/ZayZGS9yH4fR00aFC8x/Tr1887PnDgwLhjx44d85199tm+mJgY3/Lly+OOx8bG+jp06BD3XMnVrFkz73x7X4IdOXLEV7JkSV/OnDl927dv947t3Lkz7utgixYt8mXJksV32223xTs+atQo77ntNuHPxrZg9vOzc2+//fZ4x+fMmRP3PSV8nt9+++2Ettg1U6ZMGd+5554b73hS10nC1w/+Ga9fv96XLVs2X4kSJXwbN26MO37w4EHfVVdd5Z0/duzYVP8sT8bfnvfff/+k56W0jW3btvWOff311yc817///hv3de/evb3zpk2bdtLzACAYQwEBIAVKlSqV5F+rzz777BOO2ZA66xmxYWRffPFFsl+nf//+3l/T/Wz+i/3lfM+ePV5PUnINGTIkrkfNNGrUyPvre3BbDh06pEmTJqlEiRLeX/mD2XC5888/XymRmvfB5jtZL10wf09R8Pk2BPC3337zevKsR8zPeiSee+45r4chJfyv4Z9L5Tdz5kz9888/3ntuPSHGhpn5vw5mPTHWO7NgwQKl1tixY72f04ABA+Idt95K+5klxt6zhOyasd7JX375RRs2bFAorCfOhtLZNVGuXLm44zYszoZEmsRKwCf3Z5kWUtvGxAqR2JDS1J4HAIZgBQApYEOvgoNKsK1bt6p379664IILvDky/nks/rCyadOmZL9O9erVTzhWtmxZ79aGJCWHDXdK7MO3PU/wc1hQs3Bl84jsA2kwa78NiUqJ1LwPVatW9Yb2JWynCW6rf56OzYlJyAJj8Ifr5LDgZMPobC6Thb5TFa2wOUjXXXedF2CyZ88e973ZEL6U/HwTlnS3OXU2J82Ce0KJfa/GAubtt9/uFcOwOVb+trz66qve/altj99XX33l3Sa21poNV7TXtCFzqf1ZpoWUttEqHxobqmiVEO3n/u+//57wWBsua9+DDfm04YxWHdKGWgLAyTDHCgBSIKn5IVZ4wCa2W4U5m+tj81ws2FgPin2wszkmFl6Sq0CBAiccy5bN/co+duxYsp7DelgSY88TXATDPtgb67FKTErmxKT2fUju9+sPPydrq78gQ3JYOOrcubM3T8d6P7p3764tW7Zo9uzZXtECa7+f9erZnCfrfbOeJCsa4Q+O1iuS2h6i1Lz/NtfPSu3bY63HzOYN2XtoYcDCn83PS8n1drJ2Jfb69j3b8cTCRlpcu+nVxhtuuMGbh2Y/7+HDh+v111/3zrP38KWXXvJCobnsssu899F6Qe268M+3s2vbesL8xUAAIBjBCgBSIKlFgt955x0vTDz99NPq169fvPsGDRrkBYpI5f8gbD1NibEhccmV3u+DPyymRVv9rFfKPmhb2y1YWREDG15mwyCDe16s0IX1gHz55Zc699xz4z1HKAvZpub9tyGeVpTE2tqpU6d491llQQtWofK3y14/YVEOmyJoxxMLUadTatpovZT+YbWffvqpV9zCfvZWtMWKkfgLelhPoQVsW8fs888/9yoPvvHGG2rRooW+//77RIe8AsjcGAoIAGnAX27bX4ktmFUmi2Q2h8qGAFpgSNjLYR9OV65cGTHvgw3FTOq5rMcoJSXX/SpXruwNDbPv/9tvv/V6J/zl2BN+bza8MWGoskqKNiwvteyDvw3ZtF4o6y1LKLHvNan32X5eFhYS8s89S0mPkVWGNImVYLegcfDgwbgennAJpY358+f3wpRV+bP5fxbC7DGJzbOyoYbWo/Xoo496QWv+/Pnp8N0AiHYEKwBIA/6/lltxhWA2jGjWrFmKZBaqrBS6fbAcOnToCUUV7K/4kfI+WMEKCyFWXCL4NSxQ2Ife1A4188+luvvuu72S4DYEMGEPiO1b+AnuQbIP7tbLZaXtQ2HDEa2UvpVzDzZv3jyvlHxy32frFbTelIT8RTdSEjytdLkN4bPevOD5WtbOhx9+2PvaAkk4pbSNti5bYteIv7fQeiSN/THBfrYJ+X/2/vMAIBhDAQEgDdgHY5t7YWs02QKk9sHXCi3Yh+K2bdt6w40i2cCBA72qdo888og3jMy/jpUFGPurvq17lbAgQTjeB2uD9TBcc801Xvjxr2O1aNEir+fIFvO1XqeUsufp2bNnXG9PwqIVxr4n2+y9sSBqwwWt58JCnfWkhbIA7kMPPeS9NyNHjvQWJq5bt64Xgj788ENv6Jmtv5RwuJ/1rFkFQCu0YJXqVq1a5a2lldj5ttC0vU82ZNGCtBWTsF45+36SmotnRTHsZ2lFR+x9tdexNaJsSJxdG9ZblnAYYlp78803vWsvMbfddpsXtFPSxvvuu88LYPY4myNn74GFU1sI2not/ZUm7Tnt+rWfgwV5C1L23tp1bEMAragFACREsAKANGAfVC2Q2AdkCyj2ofvSSy/1ehzsA3KkByurpmd/pbe/8lub7XuxyoT2tRVtMMmZT3M63gcLVPYB1+ZwWdtsqJaVJLevu3TpkqrntGFh9qHcwor17ljlv8QW5LViF1Z1zwKQzcWxEGOh1IoihMLCgL1vtriyVaqzD/FWwv2DDz7wCnYkDEoW7uw9tffA3lMb6mfVGy0Y2uK4Cc+3++08+/lahTubX2QsdCQVrIxVd7RqhdYjNH78eK8n6LzzzvOGxVlISWrOYVqxHibbEmPD8ywIpaSN9v7a+2DDPufOnev9PC1gWZCy3kr/kEnrhbT3xYYG2s/FwrMVM7Fe0V69eoV9bhmAyBRji1mFuxEAgMhlH14tdNkHfKuIBwAATsQcKwCAx4bSJWQ9ANYLYr1EhCoAAJJGjxUAwGPzdGyImVXJ8687ZdXWbJichauLL7443E0EACBiEawAAJ7HHnvMm/Rv61Dt27dPxYsX9xZC7d+/v1f8AAAAJI1gBQAAAAAhYo4VAAAAAISIYAUAAAAAIWIdq0TExsZ6CwjahO30XqMDAAAAQOSymVO2/p8ttG4L1SeFYJUIC1W2WCYAAAAAGFvovmzZskoKwSoR1lPlf/PCvbq69Z5t27bNq851soQMJIbrB6nFtYNQcP0gFFw/iLTrZ/fu3V6niz8jJIVglQj/8D8LVZEQrA4ePOi1g18uSCmuH6QW1w5CwfWDUHD9IFKvn1NNEeJqBQAAAIAQEawAAAAAIEQEKwAAAAAIEcEKAAAAAEJE8QoAAAAkez2fY8eO6ejRo+lafODIkSNeAQKKVyA9r5/s2bMra9asSisEKwAAAJwyUO3cudMrY23BKr1fyz4c24Ksp6rCBoR6/RQqVEilSpVKk2uNYAUAAICT2rJlixes/EvRZMuWLd1Cj30wth6x9HwNZFy+ZF4/dt7+/fu1detWb7906dIhvzbBCgAAAEmyHqpdu3Z5C64WK1Ys3V+PYIXTdf3kzp3bu7VwVaJEiZCHBTJwFQAAAEmy+Sr2YTVv3rzhbgqQ5vLkyRN3nYeKYAUAAIBTovcIGVFMGl7XBCsAAAAACBHBCgAAAABCRLACAAAA0tHNN9+ss846K1WPffLJJxmGGSUIVgAAAMiULLAkZ1uyZIkyayDMly9fuJsRNSi3DgAAgExp3Lhx8fbHjh2r+fPnn3D8ggsuCOl1Ro4c6S1amxr9+vXTI488EtLr4/QgWEUBny/cLQAAAMh4OnXqFG9/1apVXrBKeDwhW1jWX6Y7ObJnz57qNtp6TLYh8jEUMIJ9+KF0440xuvbaIuFuCgAAQKZUv359XXTRRfryyy9Vt25dL1A9+uij3n3Tp09XixYtVKZMGeXMmVPnnHOOnn76aW9R5ZPNsfrjjz+8IYYvvviiRowY4T3OHl+zZk198cUXp5xjZfv33HOPpk2b5rXNHnvhhRdqzpw5J7TfhjHWqFFDuXLl8l7nrbfeSvN5W5MmTVL16tW9BXdtEWkLpn///Xe8c7Zs2aJu3bqpbNmyXntLly6t1q1be++F35o1a9S0aVPvOey5KlSooFtuuUXRgvgbwYYOlVautIs+h375JVbnnx/uFgEAAGQ+27dvV/PmzXXjjTd6oaFkyZLe8dGjR3tzkHr37u3dLlq0SI8//rh2796twYMHn/J5J0yYoD179ujOO+/0gs4LL7ygtm3b6rfffjtlL9eKFSs0ZcoU3X333cqfP7+GDRumdu3aaePGjSpatKh3zldffaVmzZp5Ieapp57yAt+AAQNUvHjxNHpn3HtggalmzZoaOHCg/vnnH73yyiv69NNPvdcvVKiQd5617YcfftC9997rhcytW7d6vYPWXv9+kyZNvLbZ0Ed7nIUu+x6jhg8n2LVrlw2+827D6YUXbBCg2wYNOhbWtiA6HTt2zLd582bvFkgJrh2EgusnYzlw4IDvxx9/9G5Ph9jYWN/hw4e929OtR48e3mfAYPXq1fOODR8+/ITz9+/ff8KxO++805cnTx7fwYMH44517drVV758+bj933//3XvOokWL+nbs2BF3fPr06d7xGTNmxB174oknTmiT7efIkcO3fv36uGPffPONd/zVV1+NO9aqVSuvLX///XfcsV9++cWXLVu2E54zMdbuvHnzJnm//ZxKlCjhu+iii+JdHzNnzvSe//HHH/f2//vvP29/8ODBST7X1KlTvXO++OIL3+m8fpJzfSc3GzAUMIK1aRP4eto0ymwCAIDIUqOGVLZs2m7lykkVKmTzblPyOGtLerGha9Yrk5ANV/Oznqd///1XderU8eZg/fzzz6d83vbt26tw4cJx+/ZYYz1Wp9K4cWNvaJ9flSpVVKBAgbjHWu/UggULdN1113lDFf0qVqzo9b6lBRu6Zz1N1muWK1euuOM2PLJSpUr65JNP4t6nHDlyeMMS//vvv0Sfy9+zNXPmTB05ckTRiKGAEaxiRemii3z6/vsYrVoVo02bpKB/FwAAAGG1ZYuUYCpNGoi8PyafccYZXjBIyIa2WdU+GwJow/+C7dq165TPe+aZZ8bb94espMLHyR7rf7z/sRZ4Dhw44AWphBI7lhobNmzwbs9PZL5KpUqVvOGK/mD6/PPP64EHHvCGUV5++eVq2bKlunTpolKlSnnn1KtXzxsuaEMWhwwZ4s1ts1DYoUMH7/HRgGAV4a67Tvr+e/f19OlS9+7hbhEAAIBz/DNxGvOlKmSlT1tO7Jny27lzpxcGrJfI5i1Z75H12qxdu1YPP/xwssqrZ82aNdHjbrRf+j02HHr27KlWrVp5BTfmzp2r/v37e3OyLJRWq1bNm2M2efJkrzLjjBkzvHOscMVLL73kHYuG9bQIVhHuuut8euYZ90tl6lSCFQAAiBxr1qT9c1ouOHr0qFdiPA0L16U5G9ZmRS2suIJVC/T7/fffFQlKlCjhBb3169efcF9ix1KjfPny3u26devUsGHDePfZMf/9fhY+rdfKtl9++UVVq1b1gtP48ePjzrHeLNueffZZr7hHx44dNXHiRN12222KdMyxinBVq9pY46Pe14sXW9dwuFsEAAAAf49RcA/R4cOH9cYbbyhS2mfzsKyHaJPNJwkKVbNnz06T17Ay7hbghg8frkOHDsUdt+f/6aefvLlWxuacHTx48ISQZdUM/Y+zIYwJe9sseJng545k9FhFOPtLTfPmhzRiRDYdPWoT+qTOncPdKgAAgMztiiuu8OY0de3aVffdd583lG3cuHERNRTP1quaN2+errzySnXv3t0raPHaa695a199/fXXyXoOKyTxzDPPnHC8SJEiXtEKmztlhT3q1aunm266Ka7cupVQ79Wrl3fu//73PzVq1Ej/93//p8qVK3u9kVOnTvXOtRL2ZsyYMV4obdOmjRe6rBjIyJEjvaGW11xzjaIBwSoKNG9+UCNG5I0bDkiwAgAACC9bK8oq2NmwNitgYSHL1riyAGGL3EYCW7TXeo/69OnjzWkqV66cNx/MepOSU7XQ3wtnj03Iwo8FK1v82BZNHjRokDe3LG/evF44ssDlr/Rnr2uha+HChV74tGBlxS0+/PBDr2CFsWC2evVqb9ifBa6CBQuqVq1aeu+997yFgqNBjNVcD3cjIo1VdbEfplVzsZQcTjbxcfPmrapWraS2bYuRzZ38918pT56wNgtRwq4fqwpk3fRZsjDyF8nHtYNQcP1kLDaEy+YN2Yfb4JLa6cU+mgbmWEXwJKsoZtX2rKKhzXPKaHwpvH6Sc30nNxvw2y4K2BDea691Xx84IM2bF+4WAQAAIBpYyfVgFqZmzZrllTNH2mIoYJRo08and94JVAe0MuwAAADAyZx99tnecD27tXWn3nzzTW9NroceeijcTctwCFZRwipY5s9vq3pLH39sEwml7NnD3SoAAABEsmbNmun999/Xli1bvIV2a9eureeee07nnntuuJuW4RCsooQtOG0VKydOtAXppKVLpcaNw90qAAAARLJRo0aFuwmZBnOsokibNoGvbTggAAAAgMhAsIoizZu7niszbZpVXQp3iwAAAAAYglUUsTlW/uF/toD2F1+Eu0UAAAAADMEqyrRtG/ia4YAAAABAZCBYRZlWrST/WotTptgiaOFuEQAAAACCVZQpXlyqU8d9bYtl//hjuFsEAAAAgGAVhagOCAAAAEQWglUUuu66wNcEKwAAACD8CFZRqHx56dJL3ddr10obNoS7RQAAADB//PGHYmJiNHr06LhjTz75pHcsOew8Oz8t1a9f39uQvghWke7NN5X1f/87aXVAW9MKAAAAKXPttdcqT5482rNnT5LndOzYUTly5ND27dsVyX788UcvkFmwixRLlizxguLkyZOVGRCsIpWt/vvQQ8pyzz0qctNN0l9/JTnPyqoDAgAAIGUsNB04cEBTk5hbsX//fk2fPl3NmjVT0aJFU/06/fr1814nvYPVU089lWiwmjdvnrchfRGsIpX941u40Psy66ZNirnmGum//+LuvuAC6bzz3NcrVkjbtoWroQAAANHbY5U/f35NmDAh0fstVO3bt88LYKHIli2bcuXKpXCxHjfbkL4IVpEqb15p1iz5zj7b24354Qf71+8Clzf+NtBrZZ1bH38czsYCAABEn9y5c6tt27ZauHChtm7desL9FrgseFkA27Fjh/r06aOLL75Y+fLlU4ECBdS8eXN98803p3ydxOZYHTp0SL169VLx4sXjXuOvBCOUzIYNG3T33Xfr/PPP99prPWc33HBDvJ4pm89lx0yDBg2817LNhuIlNcfKvt9bb71VJUuW9ELfJZdcojFjxiQ6X+zFF1/UiBEjdM455yhnzpyqWbOmvvjiC6WV3377zWt/kSJFvKGZl19+uT755JMTznv11Vd14YUXeucULlxYNWrUiBeKbUhnz549de6553rfU4kSJXT11VdrrRUlOA0IVpGsZEn5Zs/WsWLFAl1THTpIR496u5RdBwAACI31Rh09elQffvhhvOMWpObOnas2bdp4gcY+/E+bNk0tW7bUyy+/rAcffFDfffed6tWrp02bNqX4dW+77TYNHTpUTZo00aBBg5Q9e3a1aNHihPMswHz22We68cYbNWzYMN11111eELSgZEMVTd26dXXfffd5Xz/66KMaN26ct11gQ5wSYcMS7fF2jn3/gwcPVsGCBXXzzTfrlVdeOeF8Cy92zp133qlnnnnGC1wWSI8cOaJQ/fPPP7riiiu899oC5LPPPquDBw96QTN4iObIkSO977Fy5cre+2bDHqtWrarPP/887hx7b4YPH+79zF5//XUvCNvP7qefftJp4cMJdu3a5bO3xm7D7dixY75tc+f6YvPl8/nsx2XbHXf4fLGxvmPHfL4zznCHcuTw+XbvDndrEWns+tm8ebN3C6QE1w5CwfWTsRw4cMD3448/ercnqF7dfRhJwy02aEvRY60tqXD06FFf6dKlfbVr1453fPjw4d7nwblz53r7Bw8ePOGa/v333305c+b0DRgwIN4xe9yoUaPijj3xxBPeMb+vv/7a27/77rvjPV+HDh2843a+3/79+09o88qVK73zxo4dG3ds0qRJ3rHFixefcH69evW8zW/o0KHeuePHj487dvjwYe89yJcvn2/38Q+V/u+laNGivh07dsSdO336dO/4jBkzfCezePFi7zxrW1J69uzpnbN8+fK4Y3v27PFVqFDBd9ZZZ8W9561bt/ZdeOGFJ329ggULeu+pfS+xsbG+kK/vFGaDiOqx8neTBm+VKlWKu9/Sa48ePbwuUOuCbdeunZdyg23cuNFL+9ZFaN1/9tcE+ytENDtapYp8H30kZc/uDowYYW+WsmQJrGl1+LA3chAAAOD02bJF+vvvNN1igrYUPdbakgpZs2b1eoNWrlwZb3id9dLYMLlGjRp5+zYELot9+JJ07Ngxr0qgfR61IXopHWo26/iHNn8vk58NY0vIelz8rIfIXrdixYoqVKhQqoe42euXKlVKN1mBtOOsx8zas3fvXi1dujTe+e3bt/eG3vnVqVPHu7VevFDNmjVLtWrV0lVXXRV3zN7XO+64w/t5WFEOY9+vDZU82RBEO2f16tWp6kFMCxEVrIyNm9y8eXPctsKGvx1n41BnzJihSZMmeT9we9OsG9LPLnILVYcPH/a6TG2cqI05ffzxxxX1GjeWxo4N7A8YIHldnYFDDAcEAACnValS0hlnpOnmC9pS9FhrSyr5i1P45+vYB/jly5d7gcuCl4mNjdWQIUO8+TsWsooVK+bNj/r222+1a9euFL2ezZuykGZzloJZSEts2J59li1Xrly81925c2eKXzf49e378AdFP//QQbs/2Jlnnhlv3x+y/gsqrJZa9lqJfd8J2/Lwww97gctCmLXdOls+/fTTeI954YUX9P333+vss8/WZZdd5nXapEX4S65sijBWNcUSdEJ24bzzzjveBd+wYUPv2KhRo7w3fdWqVd4kNysjaal2wYIF3l8YbNzl008/7f0g7I2N+mooN97o/hrTq5fbv/tu1ZtYQoULt/UKBtofPw4dsr+ohLuhAAAgU1izJu2f0+fzRhvZZ0KvWtdpUL16dW+U1Pvvv+/NUbJbn88Xrxrgc889p/79++uWW27xPl9aoQULJtbLZKErvdx7773eZ157ndq1a3tzoWxUl4W+9HzdYP5wmZC9R6fLBRdcoHXr1mnmzJmaM2eOPvroI73xxhte6LT5Vub//u//vJ4vu8/modm8sOeff15TpkzxCo1kumD1yy+/qEyZMl4lD7t4Bg4c6KXkL7/80uv+bGw9N8fZPwC7z7puLVjZrVVqsVDl17RpU3Xv3l0//PCDqlWrluhrWlUW2/x2797t3drFerou2KTY69tFG9eO++5TjJVfHzzY+8WTtUsHPVBvjvrNqy9b227+/FhZZXYg0esHSCauHYSC6ydj/jz92+ngf53T+cG9Q4cO3od0q/Jnf8i3XhGrOudvgy1yaxX33n777XiPs54j60VK2Obg9yvhrX1+tfd1/fr18Xprfv755xMea6/bpUsXrzJf8PQYe93g5/Q72c/Jf7x8+fJeT5uN9grutfIXebD2JWx/Ys95qmvCd4rH+9tigSnh/QnbYmyqj4Un22yEmk0LsmIXjzzySFw5+9KlS3tFNu655x6v8qGFZjvH1iJLqo3+31dJ/c5K7u+yiApW1mVnQ/fsArNhgJY+bQyndelt2bLF63GysZPBLETZfcZug0OV/37/fUmx8OZPusG2bdvmXbjhZD9I662zH3jchd+rlwr+8YdyT5qkmEOH1Gd5a03UCn2vi/X++wdVo4YLhkCi1w+QDFw7CAXXT8Zif9i2n6n1Ip2Oeet23dgHfpOwRHl6snlEFqysV+rrr7/2boO/X7uW/e+Dn4Wev//+2xvS5z/uvw0+1//B3L9vJcAfe+wxrwKfVfrzs6GGCR9rvUUJX9ceZ+9R8HF/sLA5WAl/Tv5g4j9uHQ820ssCpPV8+e+zcuY23O7KK6+M9/NO+Pp+SR338/8c7Tap8yzw2Htg03+so8TY2mFWBfCss87Seeed5z3Wvq/gRZrt52GZYfbs2d5wSbtWbH6YlcH3v671KlrQss/zSb2+Hbfvw57f5pklxsq4R12wCu6iq1Klihe0LMVa+cvgiXtprW/fvurdu3e8Hisbx2rjV+2HE072g7YLxdoS739O48bJt2ePYubMUc4DuzU3pplq+z7T/PlnqmjRXEqixxaZTJLXD3AKXDsIBddPxmIfSu2DpQ3N84bnnSZJfchNL9ZDZWW/bT6/6dy5c7zv18qs2xBAK6pgo6qs1LoFE5vPY9e7/1z/rV37wV8H32c9YVY4wkqD23trz7do0SKvByvhY+1133vvPa9zwUqN2xQYm/ZiISP4POuZsRD20ksveQHD5mPZ9Bkr5uYPqP5zrSy59bxZyXcLkRZgbPic1SiwcOefQ5XY9xIsqeMJhxDaQss2Ki2hrl27ep/DP/jgA7Vq1cob9mhhaOzYsfr999+94OqfymN1FGy6kP2MrOPEerSspLodt/ZaD559H9dff71Xs8GGTNpwwDVr1ni9fUm1047b92HvZ1KLOCd3ceeIClYJ2QVkKdUuMkv21uVnb1pwr5VVBfTPybJbqwQSzF81MLF5W3524dmWkL3JkfA/BPvHcEJbrL2TJ0s232z1apXxbdJcNdVV21Zo5cpiqls3nC1GJEn0+gGSgWsHoeD6yTjsZxhcsTm9We+K/3VOZ4+VsTlVFi78BRKCWQ+TrRtlYcqCwKWXXuotYmvD0ILbGnyb2DG/d9991/vjg4UmWx/LQpA9n/1xP/ix1jtlAcVe10Ku9SZZsLJep+DntJ4ZC2o2EssCk/XaLF68ON5oLv+5NqTOFg+2tluIsU4F6/2xuVy2llXC85P62Z/qmog5ft/EiRMTvd+GVtqcKHvPrSbCa6+95n2P1sFiATd4XS8b3mfvlQU/C45ly5b1qhj269fPe528efN662BZT5zNqbI/8Fj1RJuHZdOCTtbGU/2+Su7vsRirua4IZW+ajau0whOWaO3is8mENp7S2HhMm2fln2NlXYGW6m0YoaVzY6tEW8l1G2OZWHhKjF1clnJtGEMk9FhZ2+37SfSH+u+/kpWnXLfO2/1ctTSlxyI9/1re099YRJxTXj9AErh2EAqun4zFPuha70GFChWS/Zf7UPiCilec7mCF6OdL4fWTnOs7udkgon7b2erIVkbdatZbcrVVky2hW1epfTO33nqrN2TP0rcVs+jWrZvXdeofj2krV1sXqXXd2sRDW8HZUqyVY0xuqIo6xYpJc+cqtlRpb/cyrVazd26Q73DoK2EDAAAASJ6ICla2ZoCFKOuKtGofNtbRxpFaT5Wxrj/rkbIeq7p163rD+6yrz89CmJVgtFsLXJ06dfKqqAywNZ8ysvLllWXuHO3NVtDbbXBwtnZcf7tXNRAAAABA+ouoOVZJjb/0s+45m6RmW1Ks2IV/NetMpUoVLbhnupoNbapcOqSiM8ZIfUtJgwaFu2UAAABAhhdRPVYIzWUP1VMnvadYHR9P+vzzUtCaBwAAAADSB8EqAyldWtpUu516KKhH78EHpTffDGezAAAAgAyPYJXBtGkjDVd39dPTgYN33y2NHRvOZgEAgCgXwYWkgYi4rglWGTBYmWf1mMaWcesqeLp1c+teAQAApIB/kdcjR6g4jIzn6NGj3m1aLH5NsMpgKlaULrrIvopR103PaW+3e9wdsbHSTTdJn3wS5hYCAIBokj17dm/ZGlvDh14rZDS7d+/2/njg/wNChqkKiLTrtfr+e/sqRk8WekUvdtsnjRplkVyyxZWtamLDhuFuJgAAiBLFihXT33//7S2NY2uLWthKr8V7WSAYp+P6sfP27dvnBavSpUunybVGsMqAbrxReuYZt4zVS0OyqMRzI/VQ+/3SBx9Ihw5J114rzZ8v1a4d7qYCAIAoUKBAAe/233//9QJWerIPvLGxscqSJQvBCul6/dj9hQoV8v5YkBYIVhlQ5crSq69K9xwfBfjwo1mV/5Vx6r5/vzRjhrRvn9S8ubRokXTppeFuLgAAiJJwZZvNtTp27Fi6vY59KN6+fbuKFi3qfTgG0uv6sZ7XtBgC6EewyqB69JD27JH69nX7d9+fXflGfKjOB1pJCxZIu3ZJTZpIS5dKF14Y7uYCAIAoYR9GbUvPD8b2/Lly5SJYIaquH67WDOyRR6RHHw3s33xXLk3tOk268kp3YPt26eqrpfXrw9ZGAAAAICMgWGVwNtfqvvsChQHb35JX8+7/RKpe3R3cvFlq1EjauDGs7QQAAACiGcEqg7M5e0OGuGWsjC1B0bpLQa3oP9dfl92FqsaNpS1bwtpWAAAAIFoRrDIBG146cqT0f//n9g8elJp3Kqq1z8+Xzj3XHfzlFxeubHggAAAAgBQhWGUSVvBk3DipRQu3v3ev1KhjKf346kKpfHl38IcfpKZNXWELAAAAAMlGsMpEcuSQJk2SGjRw+zt3SvU7l9NvIxZIpUu7g19+6dKXlWQHAAAAkCwEq0wmd27p44+lyy93+9u2SfVurai/xyyQihZ1Bz/9VGrd2o0ZBAAAAHBKBKtMKF8+adYsqWpVt//XX1Lduypr23vzJP/K0wsXSjfcIB0+HNa2AgAAANGAYJVJFS4szZ0rVark9n/7Tarf+1LtfH+2lDevOzhzptSpk3T0aFjbCgAAAEQ6glUmVqKENH++dNZZbv/HH6WGj9XW3vdnSLlyuYM2KevWW90iWAAAAAASRbDK5MqWdaP+ypRx+199JTUd1EAHJ0yRsmd3B8eOlXr0kHy+sLYVAAAAiFQEK+jss6UFC6Rixdz+Z59JLV9vrkNjP3B12s3w4VKfPoQrAAAAIBEEK3guuECal6B2RdtxbXT03bFSTIw7+PLL0hNPhLWdAAAAQCQiWCFOtWrSnDmuaqCxyoH/N62Djr45InDS009Lzz8ftjYCAAAAkYhghXhsfSsrBmjrXZmpU6UuS29T7JBXAic98oj06qthayMAAAAQaQhWOEG9etK0aVKOHG7//fel2769T7HPPhc46b77pHffDVsbAQAAgEhCsEKimjSRJk+WsmVz+6NGSff81Ve+Rx8LnHTbbS51AQAAAJkcwQpJatXK5aYsx6+SN9+U+hx4Wr77e7oDViGwc2fXvQUAAABkYgQrnNT117tlrOIKAw6JUf+8L0t33OEOHDsmtW8vzZ0b1nYCAAAA4USwwil17CiNHBnYf/a5GD1b9k2pUyd34PBh6brrpKVLw9ZGAAAAIJwIVkiWW2+VXnstsN/v8SwaUmWU1K6dO3DwoNSypbRqVdjaCAAAAIQLwQrJ1qOHNHhwYL/3Q9k0vO4E6Zpr3IG9e6XmzaWvvgpbGwEAAIBwIFghRfr0kZ56KrDf/f4cGtNqstSwoTuwc6crKfjjj2FrIwAAAHC6EayQYv37uzWC/brdnVsfdpwuXXGFO/Dvv1LjxtL69WFrIwAAAHA6EayQYlYh8LnnpPvvD1Rd73BHPk2/c5ZUvbo7uHmz1KiRtHFjWNsKAAAAnA4EK6Q6XA0ZIt15Z6Dq+g23FdS8B+ZKF13kDlqosnBlIQsAAADIwAhWCClcvfGG1LWr2z9yRLq2W1Et6z9fOu88d9CGA9qwQBseCAAAAGRQBCuEJEsW6Z133BrB5tAhqdnNpfT5swuk8uXdQStkYQUtrLAFAAAAkAERrBCyrFmlcePcGsHmwAGpcbdy+uqlRVKZMu6glWC3Uux79oS1rQAAAEB6IFghTWTPLk2c6LKTf0mrBreerR+GLZSKF3cHbfHga691yQsAAADIQAhWSDM5c0offRRY0mrXLqnuHZX0yxvzpcKF3cElS6S2bd2YQQAAACCDIFghTeXOLX38sXTVVW5/xw7pqh6X6I/hc6T8+d3BOXOkm26Sjh4Na1sBAACAtEKwQprLm1f65BOpVi23v3WrdGWvWvp7xCcueZmpU105QavTDgAAAEQ5ghXSRYECrmOqalW3v2mTdMXDdbR15HQpRw53cMIE6a673ArDAAAAQBQjWCHd2LSqefOkCy8MrBd8xRNXa/tbk6Rs2dzBt9+WevYkXAEAACCqEayQrqwg4IIFgfWCf/1Vuur5a7Xr9fFuESwzbJj02GNhbScAAAAQCoIV0l2pUtLChVKFCm7/55+lOq+1195X3gmcNHCg9OyzYWsjAAAAEAqCFU6LsmWlRYvcrfnuO6n+6Ju1f/DrgZP69ZOGDg1bGwEAAIDUIljhtDnrLBeurAfLfPml1HjK3Tr49AuBk3r1kkaMCFsbAQAAgNQgWOG0OvdcNyywWDG3v3Kl1GzBgzry6BOBk6xS4PjxYWsjAAAAkFIEK5x2lSu7ghZWNdAsXSq1WP2Ejvbs4w5YhcCbb5amTAlrOwEAAIDkIlghLC65RJo71613ZeYviFGbX17QsTvvdgds4eAbb5RmzQprOwEAAIDkIFghbGrWdLkpb163P/OTGN247VXFdrnZHThyRGrXTlq8OKztBAAAAE6FYIWwuvJKacYMKVcutz95ShZ1PfK2Ym/4P3fg4EGpVSvps8/C2k4AAADgZAhWCLsGDaSpU6UcOdz++Pezqnu+8fK1bOUO7NsnNW8urV0b1nYCAAAASSFYISI0ayZNmiRly+b2R4zKrp5lPpSvcWN3YPduqUkT6fvvw9pOAAAAIDEEK0SMa6+VJkyQshy/KoeNyKXHKk+T76qr3IHt2yULWr/8EtZ2AgAAAAkRrBBRbrhBGj1aiolx+wOH5dWztT+RatRwB/75R2rUSNqwIaztBAAAAIIRrBBxOneW3norsN9/cAG93HSudPHF7sCff0oNG0qbNoWtjQAAAEAwghUi0u23S8OGBfYfeLaIhrebL51/vjvw229uWOC2bWFrIwAAAOBHsELEuvde6YUXAvvdnyypMZ0XSBUquAM//SRdfbX0339hayMAAABgCFaIaA8+KD31VGD/5n5l9eGdC6UzznAHvvnGlWLfsydsbQQAAAAIVoh4/ftLjzwS2L+xbwXN6LlQKlHCHfj8c6llS2n//rC1EQAAAJkbwQoRzyoEPvecdP/9bt/nk9o8cr7mPzRfKlzYHVy2TGrTRjp0KKxtBQAAQOZEsELUhKshQ6S77nL7x45JLfpW0fJ+c6X8+d3BefOk9u2lI0fC2lYAAABkPgQrRFW4ev116eab3b7lp8Z9a+qLp2ZJefK4g9OnS126uOQFAAAAnCYEK0SVLFmkt9+WbrzR7R8+LNV77Cp9M2C6lDOnOzhxoqvXHhsb1rYCAAAg8yBYIepkzSqNHeumVJkDB6Srnmysn575SMqWzR0cNUq67z43IQsAAABIZwQrRKXs2aX335euucbt790r1X6mhX57ZoLr1jI2btDKCRKuAAAAkM4IVohaNvLvo4+kRo3c/q5dUs0XbtCfA0YFTrIVhp9+OmxtBAAAQOZAsEJUy5XL1auoU8ft79ghVX+li7Y88WbgpCeekF56KWxtBAAAQMZHsELUy5tXmjlTuuwyt79tm1R95F36t29QmOrTR3ozKGwBAAAAaYhghQyhQAFp9mypWjW3v2mTVP293trZe0DgpLvvlsaMCVsbAQAAkHERrJBhFC7s1gi+6CK3v3GjVGNaP+3p8UjgpFtukT74IGxtBAAAQMYUscFq0KBBiomJUc+ePeOO1a9f3zsWvN11113xHrdx40a1aNFCefLkUYkSJfTggw/q6NGjYfgOEA7FikkLFkjnnef2f/0tRrUWPKf9t93nDtjaVp06STNmhLWdAAAAyFgiMlh98cUXeuutt1SlSpUT7rv99tu1efPmuO0Fq/p23LFjx7xQdfjwYX322WcaM2aMRo8erccff/w0fwcIp5IlpYULpQoV3P7P62JUe9UQHex4qztgQfv666X588PaTgAAAGQcERes9u7dq44dO2rkyJEqbGO7ErCeqFKlSsVtBWxyzXHz5s3Tjz/+qPHjx6tq1apq3ry5nn76ab3++ute2ELmUbastGiRVK6c2//2+yyq8+NbOnx9B3fArofWraXly8PaTgAAAGQM2RRhevTo4fU6NW7cWM8888wJ97/33ntecLJQ1apVK/Xv398LW2blypW6+OKLVdK6LI5r2rSpunfvrh9++EHV/JUNEjh06JC3+e3evdu7jY2N9bZwstf3+Xxhb0c0OvNMNyywfv0Ybd4cozVfZVXD7KO0uMU+Zf9kunTggHzXXCOf9VzVqqWMiOsHqcW1g1Bw/SAUXD+ItOsnuc8VUcFq4sSJWrt2rTcUMDEdOnRQ+fLlVaZMGX377bd6+OGHtW7dOk2ZMsW7f8uWLfFClfHv231JGThwoJ566qkTjm/btk0HDx5UONkPcteuXd4FkiVLxHUwRjzr0Jw4Mavati2i7duz6tPVOdSo1jjNqdtaeZYtVszevfI1a6YdkyfrqL/qRQbC9YPU4tpBKLh+EAquH0Ta9bNnz57oClZ//vmn7r//fs2fP1+5bNXXRNxxxx1xX1vPVOnSpdWoUSP9+uuvOuecc1L92n379lXv3r3j9ViVK1dOxYsXjzfUMFwXhxXpsLbwyyV1SpRw06kaNfLpv/9itHx1ft3QYKY+rttSWZctVpZdu1T0ppvkW7xYqlxZGQnXD1KLaweh4PpBKLh+EGnXT1LZJGKD1ZdffqmtW7fq0ksvjVeMYtmyZXrttde8oXpZs2aN95jLjq8Iu379ei9Y2fDA1atXxzvnn3/+8W7tvqTkzJnT2xKyH0Yk/IO2iyNS2hKtbBSolWJv1MiCszRrcR61b/qxPry8ibKsWqmYf/9VTJMm0rJlUsWKyki4fpBaXDsIBdcPQsH1g0i6fpL7PBFztVrP03fffaevv/46bqtRo4ZXyMK+ThiqjB031nNlateu7T2HBTQ/6wGzXqfKGawnAilXo4ZbRDhvXrf/0dx86lp8tnzVjof5zZtd8tqwIaztBAAAQPSJmB6r/Pnz66IEc1zy5s2rokWLesdtuN+ECRN0zTXXeMdsjlWvXr1Ut27duLLsTZo08QJU586dvTLsNq+qX79+XkGMxHqkkPlccYX0ySdS8+Ze7QqNn1FQudvO01tH6ivm++/dqsIWrqznqkyZcDcXAAAAUSJieqxOJUeOHFqwYIEXnipVqqQHHnhA7dq104yghV6tV2vmzJnerfVederUSV26dNGAAQPC2nZElnr1pGnT7Jpy+yOnFFWvC+fLF7eq8K8uXAX1fAIAAABR0WOVmCVLlsR9bcUkli5desrHWNXAWbNmpXPLEO1sOtVHH0lt2rj1gl/5oJRyd1qo547UVczvv0s//+xOssWwihQJd3MBAAAQ4aKmxwpIay1bWil26+l0+4PGl9XT9RbKd8YZ7sA337gxg8fXNQMAAACSQrBCptaunTR2rFWPcftPjK6gl1ssks+/HppVmbQEtm9fWNsJAACAyEawQqbXoYP0zjuB/T4jztPwdgukokXdgeXLpeuuk8K8WDQAAAAiF8EKkNStm/TGG4H9u9+4SKNvmiv5F4hesEC6/nrp8OGwtREAAACRi2AFHNe9u/Tyy4H9bq9V14fdgha+sjrtHTu6ahcAAABAEIIVEKRXL2ngwMB++1eu0Iw7Zki5crkDkye77q3Y2LC1EQAAAJGHYAUk8Mgj0uOPB/avHdJA8++eKmXP7g6MHy/ddZfk84WtjQAAAIgsBCsgEU8+KT30UGC/2dBmWnbPh4Ha7CNHSj17Eq4AAADgIVgBibDy64MGSffd5/Zt5F/DYddp9X3jpSzH/9kMG+a6twhXAAAAmR7BCjhJuBo6VLrjDrd/7Jh01Ws36uv73w2c9MIL0lNPha2NAAAAiAwEK+AU4erNN6WuXd3+kSPS5W901U/3vRk4yYLV88+HrY0AAAAIP4IVcAo28s8WEL7xRrd/6JBUfeRdWt9jSOAkGxL4yithayMAAADCi2AFJIPVrBg7VmrTxu0fOCBVHd1Tf9wZVJvdilm89VbY2ggAAIDwIVgByWTV1idOlFq0cPv79klVJjyiv28Nqs1uZdjHjAlbGwEAABAeBCsgBXLkcGsEX32129+zR7po8pP6p8uDgZNuuUX64IOwtREAAACnH8EKSKFcuaRp06T69d3+zl0xunDm8/q3w72B2uwdO0pTp4a1nQAAADh9CFZAKuTJI82YIV15pdvfviNGF85/RTtvuD1Qm719e2nWrLC2EwAAAKcHwQpIpXz5XG6qVcvtb90WowuXD9fu6zoHarO3bSstXBjWdgIAACD9EayAEBQoIM2ZI1Wr5vY3bcmiS9a8q33X3BCozX7ttdLy5WFtJwAAANIXwQoIUeHC0rx50sUXu/0//sqmqj+8p/1NWrsD+/dL11wjff55WNsJAACA9EOwAtJAsWLSggVSpUpuf/2G7Kr56wc62KCZO7B3r9SsmfTVV2FtJwAAANIHwQpIIyVKuOlUFSu6/R9/zanL/56iw1c2cAd27nR12r/7LqztBAAAQNojWAFpqEwZadEi6ayz3P43/8utq3Z8rCO1/OUDt0uNG0s//RTWdgIAACBtEayANFaunAtXdmu++CmfGh6cpaOX+ssHbpUaNZJ++SWs7QQAAEDaIVgB6aBCBReuSpd2+yu+LaBmmqNjVY6XD9y8WWrYUPr997C2EwAAAGmDYAWkE5trZeHK5l6ZhWsLq2XO+Tp24fHygX/9JTVoIG3cGNZ2AgAAIHQEKyAdWZVAK2hRtKjbn/NFUbXNv0CxlSq7Axs2uHD1999hbScAAABCQ7AC0tlFF0nz50uFCrn9j1eVUPuiCxRb8Vx34Lff3LDALVvC2k4AAACkHsEKOA2qVXOLCBco4PYnf1pancssUmyFs92B//3PFbTYti2s7QQAAEDqEKyA06RmTWnuXClfPrc/YVlZ3XrWIvnKnekO/PijK8VuJdkBAAAQVQhWwGl0+eXS7NlS3rxuf/Ti8rrr/MXynXGGO/Dtt1KTJm4xYQAAAEQNghVwml11lTRzppQ7t9sfseBs3XfRYvlKlXIH1q6VmjaVdu8OazsBAACQfAQrIAzq15c+/ljKlcvtvzb3XPWptki+4sXdgdWrpWuukfbuDWs7AQAAkDwEKyBMbDrVtGlSjhxu/+XZF+ixyxbK56/N/umnUqtW0v79YW0nAAAATo1gBYSRjfj76CMpe3a3P3DmxXrqyvny+WuzL1kitW4tHTwY1nYCAADg5AhWQJi1bCl9+KGULZvbf+rjahpYf558/trsCxZIbdtKhw6FtZ0AAABIGsEKiADXXSe9/76UNavbf2xaTb3ceLZ8/vKBVkrwhhukw4fD2k4AAAAkjmAFRIjrr5fGjZOyHP9X2WfKFXqt+Sz58uRxB2bMkNq3l44cCWs7AQAAcCKCFRBBbrpJGjVKiolx+/dNrquRrWbI5y8faNUubryRcAUAABBhCFZAhOnSRXr77cD+nR801Oi2MwK12adMkTp2lI4eDVsbAQAAEB/BCohAt9wiDR8etD+hscZdP13KmdMdmDRJ6tyZcAUAABAhCFZAhLrzTunVVwP7XcY30YQbpgYWvpo4UeraVTp2LGxtBAAAgEOwAiLYPfdIQ4YE9juOb64P2wctfDVhgtStG+EKAAAgzAhWQITr2VN68cXAfvtxLfXRTZMD4cpKCd52mxQbG7Y2AgAAZHYEKyAKPPCA9MILgf3rx16raR2CVhUePVq64w7CFQAAQJgQrIAo8eCD0sCBgf02Y67TjI4TA6sKv/OO1L074QoAACAMCFZAFHnkEemZZwL7145pp086TgiEqxEj3MQsny9sbQQAAMiMCFZAlHnsMWnAgMB+y7H/pzmdxktZjv9zfvNN6d57CVcAAACnEcEKiEL9+0tPPBHYbz7mRs3vPDYQrl5/XerVi3AFAABwmhCsgChlwapfv8B+kzEdtajzKCkmxh145RXF2MQswhUAAEC6I1gBUcrykw0JfPTRwLFGY7poSed34sJVzJAhyv/004QrAACAdEawAqKY5ScrZvHww4FjDcZ20/IuI+P28775pmLsBMIVAABAuiFYARkgXFkZ9j59Asfqjb1Vn3Z5K3DOSy+5eu2EKwAAgHRBsAIySLiyBYR793b7lp/qjLtDn3Z5M3CShStLX4QrAACANEewAjJQuHrxRen++4PD1Z1adOPQwEkvvyw98ADhCgAAII0RrIAMFq6GDHHLWBmfL0aNP7hPn3ULDAv0TrCuLcIVAABAmiFYARkwXL3yitSjRyBcXTX6dn12y9uBUuxDh7LOFQAAQBoiWAEZkOWnV1+V7r7bFwhXo27Vp92CwpWlL8IVAABAmiBYARmU5adhw3y65ZZ9gTlXo27Rim7vxA9XPXsSrgAAAEJEsAIy/DpXe3TPPf6eK6nuqG5advO7gXA1bJireEG4AgAASDWCFZDBWX4aOtSn++5z+5af6o++Wcu6jQqEKxs3aBUvCFcAAACpQrACMk24il+Kvd67XbW02+hAuHr9demeewhXAAAAqUCwAjJZKXabUuVX/90uWtJtTCBcvfGGKycYGxu2dgIAAEQjghWQiVh+sjWCbRkrvwbvdtaim8dKWY7/OnjzTcIVAABAChGsgEwYrl58UXrggcCxRqM6aWHXoHA1fLjVaidcAQAAJBPBCsik4WrwYKlPn8CxxqM6akHXcYFw9dZb0h13EK4AAACSgWAFZOJw9cIL0oMPBo5dPaqD5ncdHwhX77wjdesmHTsWtnYCAABEA4IVkMnD1fPPSw89FDjWZNRNmnvz+1LWrO7A2LFSp07S0aNhaycAAECkI1gBmZyFq0GDpIcfDhxr9u7/adYtk6Ts2d2BiROlG2+UjhwJWzsBAAAiGcEKgBeuBg6UHnkkcKzFyDb6+OYpUo4c7sBHH0nXXy8dOhS2dgIAAEQqghWAuHD13HNS376BY61HttTkLh9LuXK5Ax9/LLVpIx08GLZ2AgAARCKCFYB44erZZ6X+/QPHbni7qd7r8ImUJ487MHu21KqVtH9/2NoJAAAQaQhWAE4IVwMGuM2v07sNNer/ZsuXN687sGCB1KKFtHdv2NoJAACQYYLVxo0btWLFinjHvvnmG3Xp0kXt27fXtGnTUv3cgwYNUkxMjHr27Bl37ODBg+rRo4eKFi2qfPnyqV27dvrnn39OaFOLFi2UJ08elShRQg8++KCOUs0MSDHrtbKiFn63jK6rEe3myVeggDuwZInUrJm0e3fY2ggAAJAhgtV9992nJ598Mm7fQk6DBg00ZcoULVu2zAs+9nVKffHFF3rrrbdUpUqVeMd79eqlGTNmaNKkSVq6dKk2bdqktm3bxt1/7NgxL1QdPnxYn332mcaMGaPRo0fr8ccfD+XbBDItqxT48suB/bvGXqFXW82Xr1Ahd+DTT6UmTaSdO8PWRgAAgKgPVqtXr9bVV18dtz927FgdOHDA67X6+++/1ahRI7344ospes69e/eqY8eOGjlypAoXLhx3fNeuXXrnnXf08ssvq2HDhqpevbpGjRrlBahVq1Z558ybN08//vijxo8fr6pVq6p58+Z6+umn9frrr3thC0DK9eolvfZaYP/+92rpxWYL5StSxB34/HOpcWNpx46wtREAACDcsoXy4B07dnjD7fxmzpypevXq6ZxzzvH2rTfp0UcfTdFz2lA/63Vq3LixnnnmmbjjX375pY4cOeId96tUqZLOPPNMrVy5Updffrl3e/HFF6tkyZJx5zRt2lTdu3fXDz/8oGrVqiX6mocOHfI2v93HhzbFxsZ6WzjZ6/t8vrC3A9Epra6f7t3desHdu7u/xTw08VIdumGRHltytWK2bbN/oPI1bCjf3LlS8eJp1HqEE797EAquH4SC6weRdv0k97lCClbFixfXhg0bvK937tzp9RzZ3Cg/m9uUkvlNEydO1Nq1a72hgAlt2bJFOXLkUCH/EKTjLETZff5zgkOV/37/fUkZOHCgnnrqqROOb9u2zZvXFU72g7TeOrtAsmSh1gjCd/1cd53Nc8yt3r0LyOeLUf9Jl2h3i9kauLq5sm7bpphvvtHRevX036RJiiVcRT1+9yAUXD8IBdcPIu362bNnT/oHK+s9GjZsmAoUKKAlS5Z438h19unrOBuWV65cuWQ9159//qn7779f8+fPVy7/mjmnSd++fdW7d+94PVbWbguO9r2Fk72nVsTD2sIvF4T7+rnvPqlIEZ+6dbPnjtHgT6orpvUyDfqikWI2bVL2detU/IYb5LOqgWXKpMn3gPDgdw9CwfWDUHD9INKun+Rmk5CClfVO/e9//1OfPn283iSbT1WhQgXvPhta9+GHH6pDhw7Jei4b6rd161Zdeuml8YpRWBGM1157TXPnzvXmSVnPWHCvlRXMKFWqlPe13dq8r2D+qoH+cxKTM2dOb0vIfhiR8A/aLo5IaQuiT1pfP1262L8ZqWNH+zcqvTC9kg63WqaXszVUzMaNilm3TjH16kkLF0pnnZUmr4nw4HcPQsH1g1Bw/SCSrp/kPk9IwcqG2X366aded1vu3Lm9cBWcFhcuXJjsHisrdPHdd9/FO9atWzdvHtXDDz/sPU/27Nm957Rqg2bdunVeefXatWt7+3b77LPPegHNP/fLesCs16ly5cqhfKsAgrRvL2XP7m5ttO/QGefo8DVL9VrWhor5/Xfpt9+kOnVcuDrvvHA3FwAAIN2FFKz8ChYseMIxC1qXXHJJsp8jf/78uuiii+Idy5s3r7dmlf/4rbfe6g3ZK1KkiBeW7r33Xi9MWeEK06RJEy9Ade7cWS+88II3r6pfv35eQYzEeqQApJ6tdGCrKVx/vWRFN9+YdZYONV2mkdkbK+Z/66S//pLq1rW/bkgXXxzu5gIAAKSrkPrHrPdo8ODB8Y69++67XqU+682ydadsOF9aGTJkiFq2bOn1WNWtW9cb3he8TlbWrFm9yoR2a4GrU6dO3mLFAwYMSLM2AAho1UqydcD9f7d4Z25ZdTpzmWIvPr4GnQ3FtWGBiRSkAQAAyEhifFYyI5Xq1Kmj8uXLe+tGGRvKZ3OkbGHfihUravLkyXruuee8oXzRxIpXWC+cDXGMhOIV/qGNjDNGpF4/Vqvi2mulAwfcftv6O/Th3ubKuub4nMf8+W09BteDhajA7x6EgusHoeD6QaRdP8nNBiG92k8//aQaNWrE7Y8bN857seXLl+uDDz7Q7bff7i0aDCBjs+XlZs2y4btuf8qSIrom+wIdvaqeO2BlSps1k2ydKwAAgAwopGC1b9++eKltzpw5atasmfLkyePt16xZM26dKwAZW/360rx5kv9XwryV+dVg/ywdbtTMHbDuLOvWsrGDAAAAGUxIwcoq9fkX812/fr2+//57r4CE344dOygaAWQiV1whLVpka125/RVr86j2lmk62KKtO2BVLqzaxYQJYW0nAABARAWrjh07asSIEbr22mvVtGlTFS5cWK1bt463NtV5lFoGMpXq1aWlS205Bre/9oecqv7LB9rXtpM7YAVtOnWSRo4MazsBAAAiJlg99thjeuSRR/Tnn396lQCnTZsWt3iv9VYtWbLEC10AMhdbIWH5cuvVdvs//i+bLv5yjHbfdKc7YDVz7rhDGjo0rO0EAACIiHWssmXL5i3Ia1tCttaUrSMFIHM691wXrho1kn79Vfp9QxZVPvKmvumWT0VHveRO6tVL2rvX/kpjy6SHu8kAAACplmY1LPfu3etVCbTNvgaA8uWlZcukCy5w+39vitEFMwZrS/cnAyf17y/17et6sQAAADJrsLLiFQ0aNPDmV1100UXeZl83bNhQa9asSZtWAohaZcq4OVdVq7r9bf/GqPLEJ7Tx3qDFxZ9/Xrr3Xlt8ImztBAAACNtQwM8//1z169dXjhw5dNttt+mC43+Wtl6r999/X3Xr1vXmWdWqVSukRgKIbsWLS4sXS82bS6tWSf/9J100uo++7JVX5w652530+utuWODbb9s443A3GQAAIEWyhVq84owzztCKFStUqlSpePc9+eSTuvLKK71z5s+fH8rLAMgArK6NrXNl9WyWLHFrBl8yvLs+75NXF7/czfVWjRkj7dolvf++lCtXuJsMAABweoYCWo/VnXfeeUKoMiVLltQdd9yhVfbnaQCQlD+/NGuW67nyrxlcY1gXre7zoZQ9uztoCwhfc420e3dY2woAAHDaglWWLFl09OjRJO8/duyYdw4A+OXOLU2dKrUNWjP4ipfaaXGfT6S8ed1BGzfYsKG0bVtY2woAAJBcIaWeK664Qq+//ro2bNhwwn0bN27UG2+84Q0HBIBgOXNKH3zg1gn2rxncaNDV+vj+hVLhwu7gl19KdetKf/4Z1rYCAACk+xyr5557zitQUalSJbVp00bnnXeed3zdunWaPn26smbNqoEDB4byEgAyKKtPYVOq8uSRRoxw1dZbP3eZxjy0XF3GN5E2bZJ+/lmyP87YPM3zzw93kwEAANInWFWrVs2bZ2UFKj7++GPt37/fO54nTx41a9bMK2BRrFixUF4CQAZmI4WHD3cjAIcMcce6vnChtt3zqXrPuVox69e7HqurrpLmzpUuvTTcTQYAAEhUyBOgKleurKlTp2r37t3avHmzt9nXU6ZM0YwZM1SuXLlQXwJABhYTI730kjRgQOBYn9fOUt+rVsh3ySXuwL//SvXruwWxAAAAIlCaVZawIhVWCdA2ClYASGm46t9fGjYscOz50SV1x7lLFHvlVe6A1Wdv2lT6+OOwtRMAACApJCAAEePee6Vx46SsWd3+25ML6Yb8c3WsWQt34NAhV05w7NiwthMAACAhghWAiGKVAq0cu1UONFPm5FHjPVN1+IYOgRKCXbtKQ4eGtZ0AAADBCFYAIk6rVtKcOW5BYbPk0+yq/cs47b/lnsBJvXq58YNWThAAACDaqgKuXbs22edusnLJAJAKVqti0SKpWTNp+3Zp7ddZVG3fMK3uWVQFhz7lTnrmGWnHDunVV12JQQAAgGgJVjVq1FCMzTRPBp/Pl+xzASChGjWk5culJk2kv/6S/vdLjC7+6El98WgRlXzufnfSG29I//0njR4t5cgR7iYDAIBMKsXBatSoUenTEgBIxAUXSCtWSFdfLf3yi1vW6qIR9+mLp4vorCdvdnOu3n/fdWtNnhwYPwgAABDJwaqrTRoHgNOofHnXc2XDAr/+2i1rVeWFTvrsmUK66KkbpIMHpXnz3PjBWbOkkiXD3WQAAJDJMCkBQFSwrLR4sXRV0LJWNZ9qqc8GLJAKF3YHbQ7oFVdI69eHta0AACDzIVgBiBqFCklz50rNm7t966iq9+iVmvnICqlcOXfwt99cuFqzJqxtBQAAmQvBCkBUyZNHmjZNat/e7R89Kl37SGW9e9tn0kUXuYPbtrlhgZbCAAAATgOCFYCoY8X/3ntPuusut29LWd36RFk91Xi5fHXruoP79kktW0rjxoW1rQAAIHMgWAGISlmzukrr/foFjj05tJDuLD9XsW3bBbqzunSRXniBhYQBAEC6IlgBiFq2TN7TT0uvvea+NiPH5VKbQx/oyJ09Aic+/LDUq5cUGxu2tgIAgIyNYAUg6vXoIX34YWB94I8/yap637yq/Y89GzjplVekm26SDh0KWzsBAEDGRbACkCFcf700Z45UoIDbX7kqRtU/elTbB7/rxg0aS1+2GNauXWFtKwAAyHgIVgAyjAYNpKVLpVKl3P7PP0uXDO2mP4ZNd+UEzZIlkhW42LQprG0FAAAZC8EKQIZStar02WfSuee6/b//lqo91kJfv7xIKlrUHfz2W7fW1bp1YW0rAADIOAhWADKcChWkTz+VatRw+zt3SrV7XqYFAz6TzjrLHdywwYWrlSvD2lYAAJAxEKwAZEjFi0uLF0tNmrj9gwelpveep/F3f+a6tcyOHVLDhtJHH4W1rQAAIPoRrABkWPnySTNmSB07un2rtt75odJ6/pql8jVqFEhcN9wgvfQSa10BAIBUI1gByNCsBPvYsdIDDwSOPfJcAd1fcZZiu3R1ByxQ9ekj3XOPW1QYAAAghQhWADK8LFmkF1+UBg8OHHv1rRz6v72jdKT/U4GDb7whXXedtHdvWNoJAACiF8EKQKZhnVLWe5Utm9v/aEqMGi99XHtfHyNlz+4OfvIJ5dgBAECKEawAZCqdO7t5V3nzuv1ly6Sar3bRljFzpYIF3cGvvpIuv1z67ruwthUAAEQPghWATKdZM1cxsESJwELCVXs10PcjPpPKl3cH//xTuuoqacGCsLYVAABEB4IVgEypZk1p1Srp/PPd/j//SJd1q6z5T68KLIC1e7fUvLn07rthbSsAAIh8BCsAmXoh4c8+k+rUcfv790vNbi6lkR2XSK1bu4NWJfDWW6X+/SnHDgAAkkSwApCpFSkizZsntW8fWOvqjl559ci5H8l33/2BE595xk3QOnQobG0FAACRi2AFINPLlUuaMEF66KHAsedfzKoOW4fq6ItDpZgYd/C996QmTaQdO8LWVgAAEJkIVgBwfK2r5593S1nZ12biRKnh9Pu1Z+xUKXfuQBnBK66QfvstrO0FAACRhWAFAEG6d5emT5fy5HH7y5dLNZ9prb8nLA2UEVy3zpVj//TTsLYVAABEDoIVACTQsqW0dKlUsmQgR116Z019O2KVdMEF7uC2bVLDhtKYMWFtKwAAiAwEKwBIhFVcX7lSqlTJ7W/dKtXuUEFz+n8qNWrkDh4+LN18s/TII67qBQAAyLQIVgBwknLsNtqvbt1AOfYWnQpreOvZ0t13B060yVlt20p794atrQAAILwIVgCQjHLsN97o9q1jqvt92fVQ3tcV++prUtas7g6bmHXlldKGDWFtLwAACA+CFQCcQs6crtK6jfjzGzxYun5RDx2YOlsqWNAd/PZbqVYtN4YQAABkKgQrAEgGK8E+cKD05puBTqqpU6Urn7ha/0xfJVWsGJiMVb++NH58WNsLAABOL4IVAKTAXXdJn3wiFSjg9r/6Srq0QyV9/dbnUoMGgaIWnTtLjz5KUQsAADIJghUApFDTpm60nxW3MJs2SVe0LKKpd82V7rwzcKJ1cV1/PUUtAADIBAhWAJAKlStLn3/u6lWYAwektu2za+CZb8r3yjA3dtA/XrBOHenPP8PaXgAAkL4IVgCQSsWLSwsXulF/fo8+FqObv7xXh6cFjRf8+mupZk1p1aqwtRUAAKQvghUAhFgxcMwY6dlnA8fGjpUavdBM/81eJZ19tjv4zz+uqMWECWFrKwAASD8EKwAIUUyMq1MxaZKUO7c7tmKFVKPzBfrf+NVSvXru4KFDUseOrm77sWNhbTMAAEhbBCsASCNWp2LZMql0abf/229SreZFNf/BedJttwVOfP55qUUL6b//wtZWAACQtghWAJCGatSQVq+WqlZ1+7t2Sc1b59AbVUdIr7wSWARr7lw37+r778PaXgAAkDYIVgCQxsqWlZYvl667zu3bqL8e98TovvX36dic+VKxYu6OX3+VLr9cmjw5rO0FAAChI1gBQDrIl0/66CPpoYcCx159VWr5UgPtXrRGqlbNHdy3T7rhBjdJi3lXAABELYIVAKQTW8rKplO9+66UPbs7NmeOVOuG8vrfqE+lTp3iLybcqhXzrgAAiFIEKwBIZ926SfPnS0WKuP1166SadXNr1o1jpSFDAvOuZs92865++CGs7QUAAClHsAKA08Aqrn/xhXTRRW5/926pZasYPX+op3xz50lFiwbmXV12mRtHCAAAogbBCgBOE1sreOVKqW1bt+/zuSWtOrzdUAdWfBl/3pXVbu/Xj3lXAABECYIVAJzmoha2kPCAAYFjEydKV3Yor40TVrgFhP2efVa69lpp586wtBUAACQfwQoAwlDUon9/ado0F7TMV19J1evk0dLbxkkvveROMrNmMe8KAIAoQLACgDBp3VpatUqqWNHt//uv1PjqGL2Rq3f8eVfr17v1rph3BQBAxCJYAUAYXXihtHq11KSJ2z96VOrRQ7rzw0Y6/NkaqWpVd8fevW7eVZ8+0pEjYW0zAAA4EcEKAMKscGHpk09cZvIbOVJq0O0sbfnoU+mmmwJ32DDBBg2kv/8OS1sBAEDiCFYAEAGyZZMGD5bGj5dy5XLHPvtMqlE3j9b0ek969dXAKsOffipdeqm0cGFY2wwAACI0WL355puqUqWKChQo4G21a9fWbFsw87j69esrJiYm3nbXXXfFe46NGzeqRYsWypMnj0qUKKEHH3xQR21sDQBEASsKuGKFVLas27eOqavqxGhcwXuk5culcuXcHVu3uvGDVjkwNjasbQYAABEWrMqWLatBgwbpyy+/1Jo1a9SwYUO1bt1aPwRVw7r99tu1efPmuO2FF16Iu+/YsWNeqDp8+LA+++wzjRkzRqNHj9bjjz8epu8IAFKuenVpzRrpyivd/qFDUpcuUu8PLtOR1V9JzZq5OyxQ2VpXLVtK27eHtc0AAGR2MT6fLVEZuYoUKaLBgwfr1ltv9XqsqlatqqFDhyZ6rvVutWzZUps2bVLJkiW9Y8OHD9fDDz+sbdu2KUeOHIk+7tChQ97mt3v3bpUrV07//fef13MWTrGxsV7bixcvriz+8stAMnH9RLfDh6X77ovRyJExccfq1PHp/feOqfSo5xTz5JP2S9w77jvzTPk++ECqVStNXptrB6Hg+kEouH4QadePZYPChQtr165dJ80G2RShrPdp0qRJ2rdvnzck0O+9997T+PHjVapUKbVq1Ur9+/f3hv2ZlStX6uKLL44LVaZp06bq3r271+tVrVq1RF9r4MCBeuqpp044bj+UgwcPKtwXh/0QLf/yywUpxfUT/Wwh4XPOya3+/QvoyJEYLV8eo0trxOitt3qo7sRKKtS9u7Ls2KGYjRulunW1e8AAHejaVYoJhLHU4NpBKLh+EAquH0Ta9bNnz55knRdxweq7777zgpQFmnz58mnq1KmqXLmyd1+HDh1Uvnx5lSlTRt9++63XE7Vu3TpNmTLFu3/Lli3xQpXx79t9Senbt6969+59Qo+VJd1I6LGyuWT81QapwfWTMTz4oOupat9e+uuvGG3dmlXXX19Ezz9/vXquvVy+Djcp5rPPFHPkiAr27asC33wj31tvBVYfTgWuHYSC6weh4PpBpF0/ufxVpaItWJ1//vn6+uuvvaQ5efJkde3aVUuXLvXC1R133BF3nvVMlS5dWo0aNdKvv/6qc845J9WvmTNnTm9LyH4YkfAP2i6OSGkLog/XT8ZwxRXS2rWu8roVAzx2LEZ9+sRo1aoz9e6MJcr/7CPSyy9758ZMnKiYb76RJk+Wjv9hKjW4dhAKrh+EgusHkXT9JPd5Iu5qtXlQFStWVPXq1b0hepdccoleeeWVRM+97LLLvNv169d7tzY88J9//ol3jn/f7gOAaFa8uDR3rvToo4Fjlp1qXpFdP976ktvJn9/d8dNPUs2a0oQJYWsvAACZScQFq8S684ILSwSzni1jPVfGhhDaUMKtVob4uPnz53vD+fzDCQEgmmXN6iqsT58uFSzojq1b52pWfHC0nfTll1KVKu6O/ftd/fa775bCPF8UAICMLqKClc11WrZsmf744w8vINn+kiVL1LFjR2+439NPP+2VYrf7P/74Y3Xp0kV169b11r4yTZo08QJU586d9c0332ju3Lnq16+fevTokehQPwCIVtde60qy+zPUvn3SjTdKPV8/V4eXrpRuvjlw8ptvSpdfLv38c9jaCwBARhdRwcp6miws2Twrmzv1xRdfeOHo6quv9oYILliwwAtPlSpV0gMPPKB27dppxowZcY/PmjWrZs6c6d1a71WnTp285xtgZbUAIIOpWNGqobo1rvxs5HSDFnm06dlR0jvv2Ixbd4fNubIFst59V4rsVTYAAIhKEb+OVThYVcCCBQueslb96RoKaYGzRIkSTOBEinH9ZA72W9yKAN5/v1v7ypQoIdmyVvWLfue6sn78MfAA2x8+PDCWMBFcOwgF1w9CwfWDSLt+kpsNuFoBIMrZklV33SUtXy6VK+eO2VTTxo2lwXMulm/1F1JQVVVNnCjZun6rV4etzQAAZDQEKwDIIKyAhZVkv/pqt3/smPTQQ1K7znm08/m3pA8/DPRS/f67dOWV0gsv2J/3wtpuAAAyAoIVAGQgxYpJs2dL/foFjk2deryDqvwNVk7VSqi6O44elR5+WGre3NamCFubAQDICAhWAJABS7I//bRktX0KFXLH/vjDdVC9POUs+ZYstTKsbgyhmTfPlRe0WwAAkCoEKwDIoFq2dB1UVmnd30H1wAPSte2ya/sDz9lCf7Z6emBSVtOmbuygvwIGAABINoIVAGRg5ctLy5a5vOQ3c6ZUtaq0ImcjV4bdhgL6DR4s1akj/fZbWNoLAEC0IlgBQAaXPbv0/PNu7pXNwTJ//SXVry89O7KEjk2fKb30kjvRrF6tmOrVlWvatLC2GwCAaEKwAoBMolkz10FVr16gaqAVuWh2TRZt6dDbrTZsqw5bCffdu1Woe3fF3HyztGtXeBsOAEAUIFgBQCZSpoy0cKH0xBOB2hULFrihgQv+q+7qtXfqFHd+zLhxrrDF0qXhazQAAFGAYAUAmbBq4JNPuoBVurQ7ZtXWmzSR+r+QX0dHjVPs6NGKzZ/f3blxo9SggfTgg9LBg2FtOwAAkYpgBQCZlGUlqxpoxQCNzyc984zUsKH0V4PO+nfhQvn84wbtzhdflGrWdOMJAQBAPAQrAMjESpSQZs2SBg1yPVlm+XLp0ktjNG9dRflsnKAFqhw53J3ff+/C1QsvuElaAADAQ7ACgEwuSxbp4YddWfYzz3THtm+PUefOhdXrgaw62OMBac0a6ZJL3J1HjrgHWJfX77+Hte0AAEQKghUAwHPFFdJXX0mtWweODRsW43VQfeu7WPr8cxeo/FUvrGvLCluMGuWGCgIAkIkRrAAAcYoUkaZOlV55JVY5c/rijf4b8kZOxT43yFUIPOss94C9e6VbbpHatJG2bg1v4wEACCOCFQAgHuuQuuceac6c7apSxYWrw4el3r1doYu/z67jClhYoPKbPl26+GJpxozwNRwAgDAiWAEAElWp0lGtWuXTAw8EjlktCxv999H8AtI770jTpknFi7s7rcfq2mul22+X9uwJW7sBAAgHghUAIEk5c7qigBaozjjDHduxQ7r+eqlbN2lPw9bSd99JrVoFHvT2267QxaJFYWs3AACnG8EKAHBKjRpJ334r3XBD4Njo0VLVqtLK30q6oYAjR0p587o7rVqgPejOO6Xdu8PWbgAATheCFQAg2YUtPvjABap8+dyx336T6tSRnnwqRkdvvs3NvapbN/CgESOkCy+UZs8OW7sBADgdCFYAgBQVtuja1eUnK89ubJ3gp56SrrpKWu87R1q8WHr99UDv1V9/SddcI918s/Tff2FtPwAA6YVgBQBIsbPPdlXXBwyQsmZ1x2yZKxsa+O7oLPJ1v9vVab/66sCDxoyRKld2wwYBAMhgCFYAgFTJlk3q31/69FOpYkV3bN8+6dZbpbZtpX9ynyXNneuKWRQo4E7YskW67jrpppukbdvC2n4AANISwQoAEJLLLpO++kq67bbAMavCblOrPpwU45LWDz9ILVoETpg40fVe2aQtn1srCwCAaEawAgCEzIpZWFHAqVOlYsXcse3bpfbtXSXBrTnKusWDx42TChd2J/z7r3TjjVK7dq4nCwCAKEawAgCkGRvl9+OP8cuyT57seq8mTY6ROnVyJ9hYQT9LY9Z7NXYsvVcAgKhFsAIApKnixaUPP3Sj/IoWDXRO/d//uR6sbVlLubRlJ9nJxqoFWrlBGy64YUNY2w8AQGoQrAAA6cKClHVO2Ug/P8tS1nv10ZQY161lJ1ghCz9b78p6rwYPlo4cCUu7AQBIDYIVACDdlCghTZokvf++W2DYWDHA6693eepfFZMmTHDVLkqXdifs3y899JBUvbq0cmVY2w8AQHIRrAAA6b6osNWosMKANgcruDCg9V7ZFCu1bi399JN0zz3uAea779wqxHfeycLCAICIR7ACAJwWpUpJU6ZI770XKAy4daurY9Gxo7T9aEHp1VfdSsPVqgUeOGKEVKmSeyDFLQAAEYpgBQA4bawzqkMH13t17bWB4zYa0Hqvpk+XVLOmtHq1NGSIq+PuT2BWUfDqq6X//S9s7QcAICkEKwDAaWfTqWxaVfCyVv/844YKWuXALf9mk3r2dMMDg0uzL1woXXyx9NRT0qFDYWs/AAAJEawAAGHrvbJOqO+/l1q2jF850Eb+2YLDsWXKSh995BYXPvNMd8Lhw9KTT0pVqkiLFoWt/QAABCNYAQDCqkwZ6eOPXe9VsWLu2K5d0h13SPXru04rL3lZafYHH5SyZnUn2ZDARo2kzp3dUEEAAMKIYAUAiJjeKwtRtk6w3/LlUtWqroPqULa80gsvSGvXSrVrB04aP951cQ0fLh07Fpb2AwBAsAIARAzrsRo9WlqwQDrnnMDIP5tSZQHLgpY3BHDFCumtt6RChdxJVo69e3e39tWyZWH9HgAAmRPBCgAQcWyEny1j1bevlC2bO/bzz1Ldum6I4H+7srgv7KDVavf75hupXj23cNaff4at/QCAzIdgBQCISLlzS889J335pVSrVuC4FbW44AJX5MJXoqQbCmi9VNal5ffBB9L550sDBkgHDoSl/QCAzIVgBQCIaDby77PP3NrB/mWtrDS7lWW3tbA2bpRUp460Zo0bHuivgGGB6oknXAqzyoIsLgwASEcEKwBAxLNCgPfc4woDBi8sPHOmVLmyNHSodExZ3fBAqxZ4//2B6oEbNkjXXy81buxquwMAkA4IVgCAqFGunFtY2DqgbJFhs2+f1KuXVLOmtHKl3IrDlrS+/daFKT9b88qGC957r7RjR9i+BwBAxkSwAgBEXWn2tm1daXYrBOj31VfSFVdIN9/shgp6XVnz5klTp0oVKriTrBz7a69J551HeXYAQJoiWAEAolLBgtIbb0iffipdckng+Jgxrm7FsGHS0WMx0nXXuTGEzz4r5cnjTtq+PVCefenSsH0PAICMg2AFAIhq1ktldSusuIWFLbNrl5tmdemlx5e1ypVLevRRad06qUOH+OXZ69eXWrd2XWAAAKQSwQoAEPVsrSsrbmF1K265JXDc1sKyZa06dZI2bZJUtqz03ntugWFLXX4ffyxddJF0553S5s1h+R4AANGNYAUAyDBKlJDeeccVsQjOTZalbHjgSy9JR45IuvJKafVq6d13pTPOcCfFxkojRkgVK0qPPy7t2RO27wMAEH0IVgCADOfyy11usvoURYq4Y3v3Sn36uPlYViDQK8ferZvr5rKViAsUcCfu3y89/bR0zjnS668fT2IAAJwcwQoAkCFZbrKRfZabbHkrqyZobCpVo0ZugeG//pIraNG3r/Trr25iVvbs7sRt29z4wgsvZIFhAMApEawAABla0aLSW2+5HqzLLgsc//BDNzxw4EDp4EFJxYq59a8seVnq8vvlF7fAsA0ftLlZAAAkgmAFAMgUatSQPvvMzcGyDOUf9WfFAitVkt5//3inlA0BnDhR+vxzV/nCzyZu1akjtWkj/fxz2L4PAEBkIlgBADKNLFlc1UAbHmij/GzfbNjgqrDb3CxbF8tTq5a0eLE0Y4ZbbNhv2jRXQfCuu6S//w7L9wEAiDwEKwBAplO4sFv36uuvpaZNA8dtuOBVV7mRfzblypuY1bKlW+9q5EipdGl34rFjbnyh9W717Clt2RK27wUAEBkIVgCATOvii6U5c6TZs12NCj+rVXHBBdIDD0j//Xd8oazbbnPzrZ55Rsqf35146JD0yivS2WdLDz3kCl4AADIlghUAINNr1sz1XlknlK2FZazK+ssvu2WtLDsdPiwpb17pscdcd9aDD0q5c7uTDxyQBg+WKlRw9+/YEdbvBwBw+hGsAAA43illZdnXr3fZKFcud9wyko32sx4tm17lFbgoXlx64QXpt9/cnTlzupP37XNrYp11lvTEE9LOnWH9ngAApw/BCgCAIDbKz0b7WYGLTp0Cxy1wWUHA+vWlNWuOHyxVShoyxPVg9egh5cjhju/ZIw0Y4Hqw7MlsHwCQoRGsAABIRLly0rhx0hdfSHXrBo4vWybVrCl17iz98cfxg2ecIb32mpuDZd1e1v1lrMeqf38XsJ5/3vVoAQAyJIIVAACnWP9qyRJp6lTp3HMDx8ePl847T7r33qCigGee6SZqWXdXt25S1qzu+Pbt0iOPuCIXNnHL5mQBADIUghUAAKdgVdevu076/ntXyKJIkUCBC+uosrxkuSmuZoX1UL37rvTTT248oX/BrK1bXalBm4M1cKC0a1fYvicAQNoiWAEAkEw2heq++9yUqn79XJFAYx1QNtLvhClV1sVl4wktkbVv7xKaP2A9+qjr4erbV/rnn7B9TwCAtEGwAgAghQoVkp5+OlAU0F+zYvduN6XK1g0eOlQ6ePD4A2xRrIkT3ULDN94Y6MGyBwwa5Hqw7rknaNIWACDaEKwAAEglW/PKigJazQpbP9g/pcrWCe7Vy3VYvf22GzIYtyLx++9L69ZJt98eSGSWwF5/3S2a1aWL9OOPYfueAACpQ7ACACBENqJv5EiXh6xDyu+vv1x+qlzZ5anY2ON3WIAaMcJ1efXuHRhTeOyYGzpoi2bZpK7PPw/L9wMASDmCFQAAacSqBFqA+vprqWXL+GtgdeggVasmzZhxfJFhf5n2l16SNmyQnnxSKlw48KDp06XLL5caNZIWLAh6EAAgEhGsAABIY5dc4gLUZ5+5BYX9vv1WuvZa6bLLEgSsokWlJ56QNm50QatMmcCDFi2Srr5aqlVL+ugj16sFAIg4BCsAANJJ7douF82f7xYV9rNFhy1gWQ/W5MlBQwTz5XNDA22IoI0ttCGDfmvWSNdf747ZxC5KtQNARCFYAQCQjqzCeuPGbrrUlCmuN8vPigTecIN00UXSe+9JR48evyNnTlcN4+efXTXB4AdZ5UALX+XKuZKEVvsdABB2BCsAAE5TwGrTRvrqKzd9qkaNwH3+dYStKvuoUUFVBK3MoK1/ZQ+aPVtq2jTwIFssy1YrttKDVuhiyRLmYQFAGBGsAAA4zQHLhgGuXi3NmSNdeWX8Ihe33OKy0vDh0qFDQQ9q1sw94IcfpDvukHLlcvdZmLKk1qCBG1s4enTQAwEApwvBCgCAMLCsZB1Qy5e7eVgNGwbusyKB3bu7hYaHDZP27w96oNVuf+stV8v9uefiF7qwsYXdurn67089Jf3zz2n9ngAgMyNYAQAQ5oBlnU0LF0qffuo6pvz+/lu6/36pQgVp8GBp796gB1olwb593ZyrCRPiV8fYutWVb7eAZUHL6r8DANIVwQoAgAhxxRVuKpVVDWzdOn5Oeughl5P69ZO2bAl6UPbs0k03ueoYVt/9//7Pzc0yhw+7oYE2RNDGHI4dKx04cNq/LwDIDCIqWL355puqUqWKChQo4G21a9fWbPs/zHEHDx5Ujx49VLRoUeXLl0/t2rXTPwmGOWzcuFEtWrRQnjx5VKJECT344IM6GldmCQCAyGeFLaZNcyP7LCdZr5b57z/p2Wel8uWlW291063i2ElW3/2DD1y5dktihQoF7rfQ1bWrW5S4Vy9XcRAAkDGDVdmyZTVo0CB9+eWXWrNmjRo2bKjWrVvrh+P/5+jVq5dmzJihSZMmaenSpdq0aZPatm0b9/hjx455oerw4cP67LPPNGbMGI0ePVqPP/54GL8rAABSp0oVl5Psf4NdukjZsgU6ot5915Vpv+YaN4wwXkFA69p6/nk3D+v116ULLwzcZ+ls6FBXgrBePTeMkGIXABCyGJ8vsmuzFilSRIMHD9b111+v4sWLa8KECd7X5ueff9YFF1yglStX6vLLL/d6t1q2bOkFrpIlS3rnDB8+XA8//LC2bdumHDlyJOs1d+/erYIFC2rXrl1ez1k4xcbGauvWrV7vW5YsEZWDEQW4fpBaXDuRyXLSq6+62hUJ1weuWlXq08f1cNnowHjsf/XWY2UP/PDDE4NUsWLSzTe7aoNWkjBEXD8IBdcPIu36SW42iNhgZb1P1jPVtWtXffXVV9qyZYsaNWqk//77T4WChjaUL19ePXv29HqzrGfq448/1tdBk3R///13nX322Vq7dq2q2RjzRBw6dMjbgt+8cuXKea8VCcHKQqGFSn65IKW4fpBaXDuRzZawsh6rV16J0YYNx8cJHle2rE/33uvT7bdLBQsm8uDt26Vx4xQzYoRi1q074W5fw4by2YNtbaxk/kEyIa4fhILrB5F2/Vg2KFy48CmD1fFBBZHju+++8+ZW2Xwqm0c1depUVa5c2QtL1uMUHKqM9UxZ6DJ26++pCr7ff19SBg4cqKesLG0C9kOxdoT74rAfouVffrkgpbh+kFpcO5HP6lXccIP0ySe59OabefXNN66b6q+/YvTwwzF6+ulYdehwQLfdtk/lysXGf3CHDt4TZF+5UnnGj1eumTMVc3xV4phFi7ztWLFiOnDjjTrQsaOOnXVWitrG9YNQcP0g0q6fPfbXrGSIuGB1/vnneyHK3pDJkyd7PVY2nyo99e3bV7179z6hx8qSbiT0WMXExPBXG6QK1w9Si2sneljn0m232XpYsXrppRjNnOl6sPbuzaIRI/LqnXfyyEbQ33efT5ddFiiE4bFeqeuuk2/bNvnGjFHMyJGKsVWKJWX991/le+01b/NddZV8nTq5JJfgD5yJ4fpBKLh+EGnXTy7/guzRFqysV6pixYre19WrV9cXX3yhV155Re3bt/eKUuzcuTNer5VVBSxVqpT3td2utqXsg/irBvrPSUzOnDm9LSH7YUTCP2i7OCKlLYg+XD9ILa6d6FK/vtus2N+QIa6yug26OHYsxiuA8cEHMV7V9R49XG9XnjxBD7bRHVZF0CZpLV7s5mJNnSodr6obs2KFt3mLalkYs0oaTZoEqmkkgusHoeD6QSRdP8l9nizRkDpt/pOFrOzZs2uhlT46bt26dV55dRs6aOzWhhLahDW/+fPne71ONpwQAICMrlIll4s2bnRrBFtdCr+vvnK9W2XLSg88IB3vnAqwDw+NGrkCF3/+6SoLBv//0+YjW0pr0SLwJN9+e9q+NwCIZBEVrGxI3rJly/THH394Acn2lyxZoo4dO3qVOG699VZvyN7ixYu9kuzdunXzwpRVBDRNmjTxAlTnzp31zTffaO7cuerXr5+39lViPVIAAGRUxYtLTzzhApYVuqhePX7F9ZdfdgUAmzWTZsywnq0ET2AjPawX6/vvpTVrpHvvlYoWDdxvI0LsSS65xJUktG6yBGtLAkBmElHBynqaunTp4s2zsgqANgzQwtHVV1/t3T9kyBCvnLotDFy3bl1veN+UKVPiHp81a1bNnDnTu7XA1alTJ+/5BgwYEMbvCgCA8MmdW+rWzWWjzz93awQH/61x7lzp2mulc86RBg2ywk0JnsAmZVkqGzZM2rTJrVxsa0gG13S3lYxtrrItPtyypevxCnPxJwA43SK23Ho4sY4VMgquH6QW107G9u+/rhfrzTelP/6If59VWLe1sGwu1gnFLhKWbbdhgWPGSAnmN5vYAgUUc911imnfXmrcONWl25H58PsH0bqOFVcrAACZjM27slF+Nsdq5kypefNAgDp8WBo/3uYtSzVqSCNH2oeKRJ7EhgXefbfrBvvpJxvP7+ZdHZdl927FWAUNm49lxTFuuUWaM0c6XtYdADIaghUAAJlU1qwu98yaJf3yiysKWKRI4P61a6U77pBKl3ZDCG31k0THuVjFjOeekzZskBYulK9zZ8Xmyxe4f+dOadQol+Bs7pZV0Jg3j5AFIEMhWAEAAG+O1eDBtsCwy0DWW+W3f78r327l3K3gxbPPuvNOYMNuGjaUb/Robf3uO8VayfaOHaXgkLVjh/TOO1LTpi6xWXJbsCCutDsARCuCFQAAiFfs4uabpS++cAUvbK5V8JrAv/4q9esnlS/vOqAmTXJV2E9gC2paVQwbV2jLoFjIsgW08uaNP0/LxhpakSoLWXfdJS1aRMgCEJUIVgAAIFFWDPC116TNm6X333f5xz8XKzbWTZmyQhdlyri1g7/++iRpzRYWnjDBhazJk90Dg1cptooatgCXraNlc7JsEWJLbYlO8AKAyEOwAgAAJ2WdTzfe6KZF/f679NRT0llnxR/dZ9XYq1WTLr1Uev11WysriXKCFqbatXMVBS1kWWn266934Sv4CceNc+HLKm3YsEF7UluUCwAiFOXWE0G5dWQUXD9ILa4dnIr1WC1Z4sq2f/TRictW5cjh8xYf7tgxxlvaKrhzKlF790qffOJ6s2xxrT17Ej/PFiO2IYa2WYpLsh48ohW/fxCt5dYJVokgWCGj4PpBanHtICWs6N/EiS5k2dyshKx2hY0EtClWNpwweG3hRNmkLStBOGOG9PHHSfdU2YLErVq5kNWggetaQ9Tj9w9CQbCKMAQrZBRcP0gtrh2k1nffWcDy6f33Y/XPP1kTXf7qhhtcyLrqKldI8KTsY8q337qAZZtV1EiMFcWwhYht2GCTJq7MIaISv38QCoJVhCFYIaPg+kFqce0g1Otn8+at+umnEpo4MYs3VNB6tRKy9YRt7laHDm6EX7JG9f39t1vV2ELWwoVJlCSUdPbZLmDZ1rChVLBgyN8XTg9+/yAUBKsIQ7BCRsH1g9Ti2kFaXj+WfWzalBUFtDx04MCJjzn/fBewrCfL1spKFpuXZWtg2ZNa2Nq2LemVkC+7LNCbZYt0ZcsW0veI9MPvH4SCYBVhCFbIKLh+kFpcO0iv68ey0PTpLmRZlcHElqy65BKpTRu3XXxxMnuyrJqG1Xu3J7VtxQrpyJHEz7WFuaysu79HK7jEIcKO3z8IBcEqwhCskFFw/SC1uHZwOq4fW7rKigDaGlnLliV+jk2V8oesyy9Pxpys4ARnT+oPWj/9lPS5FStK9etLdetK9epJZ56ZzBdBeuD3D0JBsIowBCtkFFw/SC2uHZzu6+fPP93SVrasVWKVBU2pUlLr1lLbti4H5ciRgkZZZcH5813IsuGDtlZWUsqXdwHLH7Qs3VHW/bTh9w9CQbCKMAQrZBRcP0gtrh2E8/qxkGXDBadMcZ1Ox46deI7VorD1sawny9bLsqKAyWZPuHatC1k2+WvVqqSHDZoyZVzI8getCy4gaKUjfv8gFASrCEOwQkbB9YPU4tpBpFw/27e75aymTnU5KOFCxMaWr7K6FNabZSGrdOkUvohV07BwZWtnWZJbuTLxF/IrViwQtK68UqpSJYXdZzgZfv8gFASrCEOwQkbB9YPU4tpBJF4/Nm1qzhwXsqwI4O7diZ9XrZrUvLnbbF5WigsAWhlDWy/LH7Q+/dS9eFJy5pQuvdRVHrQXtFsbTkivVqrw+wehIFhFGIIVMgquH6QW1w4i/fo5fFhavNiFrGnTpH/+SboAoBX+s5BlvVk2TyvFrHThV18Fgtby5YkvzBWsRIlAyLKtZk0pzJ8pogW/fxAKglWEIVgho+D6QWpx7SCarh+bMvX559KsWdLs2W76VFKsY8nfm2V5J1XLWdkLfv+9C1g2hNBefP36kz/Geq8qVw4ErVq13D5DCE/A7x+EgmAVYQhWyCi4fpBaXDuI5utnyxZXk8KCls3LSqpzqXDhQG+WLWtVtmwIL2q141evdiHLv52qVyt7dunCC93YxapV3a0t4pXJe7bCff0gusUSrCILwQoZBdcPUotrBxnl+rFRfMG9WTaiLynnnis1aCA1bOhubTRfqtmCxb/8Ej9offNN4isiJ2Tl3f1By39rFTkyyZytSLp+EH1iCVaRhWCFjILrB6nFtYOMev1s3hy/N2vXrqTPtc4kC1m2WZV16+EKiVUftHGKFrLs1lLezz+7EHYqxYsHgpY1zLZKlVJYZz46RPL1g8gXS7CKLAQrZBRcP0gtrh1khuvHOo9sipStF7xo0cmXs7LOIss1/t6sOnWk/PnToBEWtr77Tvr6axe07NZ6tux4cpx1lpurFbzZOltRPJwwWq4fRKZYglVkIVgho+D6QWpx7SAzXj/79kmffeZClm1WcT2pzqSsWV39CQtYtpRV7dquUylNWHEMG0ZoQcsftuzW5nEll00Ys5BlPVv+wHX++VKRIhE/pDBarx9EhnAGq9TUwgEAAMhwbFTd1Ve7zdgwQSv85w9a1pEUnH1sHWHb/M47T7riCrdZ2LKReqn6XGepzR5s2003uWP2d/BNm1wjfvpJ+vHHwJbYgl5//eU2G++YsP58xYqJbzapLMJDFxDJCFYAAACJKFhQatnSbcY6jGwpKwtZtoaW5Ztg//uf20aPDmQY68mykGVhy3q4Uj0lygLPGWe47ZprAsctcP39d/ygZdsPPyReldCOWVecbQnly5d44Dr7bKlMGRf4ACSJYAUAAJAMxYpJ7dq5zV/W3XqsPv3UDSH88ku3cHFwhrFKhLYZyyVWe8JClgWu6tVdbglptJIFLhv2Z5vVjg8OXLZqcnDYsuGFtt7Wxo2Jj3Hcu9cNO7QtIVvwy17jzDOl8uVPvC1XLkMW0gBSgmAFAACQCqVKSW3auM0cPOjClYUsf9jati3+8EG737ZXX3XHbLqGLVpco4YLWnZr1dZDHpFnT2ANtM0qbgQ7dEj64w8XshJuv//uGppYpQ97jG1JKVr0xNBlPV1WKt5/a71iQAZFsAIAAEgDuXK5YX+2Pfig6zT69ddAyLJbG6EXzKZHLVnituAhiBay/JuFLRuNl2bTn3LmdIUsbEvIyiJaj5Y/aFkvl4WpDRvc8R07kn7e7dvdZqXkk2LBKjhoBW/+YyVLujcPiDJUBUwEVQGRUXD9ILW4dhAKrp+k/fefK+vun+ZkvVc2RepUbL6WP2hVqSJdfLGrbZEjh06vPXukP/8MBK2Et/bNJNbjlUI++8aKF1eMjb+0cosJbxMes94yG66ITC+WqoAAAAAZny0y3Ly52/xsrpZ/iKA/bFkBwGA2X2vhQrf5WY6wTqeLLnJBy7/ZKLx0y7O2eJe/fHtibMigNd5Clm32ta3K7N/8+xbQTiLGJqtZSEtO6gx+cy1k2a0lUduS+jrh/mlPqMiICFYAAABhZNOgWrRwm59lj+CwZZsFsIQZxoYW2vbBB/FH2yUMW7ZvmSPdWdqzuVW2nWrRsOCgFfS1b/NmHd20Sdl27lSMTVKzbzS53YG2pUaePC402psXfJvYsYS3VrQjd+7AZs/l/5pKipkKwQoAACDC2FSj4FLvxnKHrRP83XeB7eef3bSohMX9bLihbcFs1Jx/apWtueX/2uZvnfYOGwsj/nLuCfhiY7X9+FCuGJtYZguKWa17C1nJuU1sXa9T2b/fbVZJMS1lz35i2ArebL6bvfkJb091zJ7XQqz/NnhL7Jj/uAU968703yb8+mT3scbZKRGsAAAAooDVdrAtuGfLQpWtnRUctmxLrHif5Q7bVqyIf9w+O1u4Cg5b/vBlvWlh/TxtL+4frpdICEuUzfGyoYbWe2VjKP3byfbta0uk9jjbEqbV1LLnsS01YS9S2c8kOVuW42Es4QWUkn1bs238eEULghUAAECUsk6ICy902403Bo7b53gbImgh6/vv3e26dW7EXWI5xIr/2fbJJ/Hvs3n6554rVahw4mZzuawSYsSxpOgPY6llc7wsYPnDVnDoSnjMhjUeOBB/s96vhMeCjye2jli0sLp3p6v23d69iiYEKwAAgAzGApEtQmxbMAtc1sNlmwUt/2b79pk/ITvfP9crqSGLiYUu22w94agt1GfD7azSoG1pzUKJ9WJZwLIAZ5utLRZ8m9TXdmubzTtLuNlzJue4hTr/Zqk6sa8Tu88fqFKyxSYIkAkD2an2rYs2ikTr5Q4AAIBUBC5bF8u2hJ9nrQBfcNDyf22V1JPqYPHXnbB1uhLrOLLPxRawzjjD3Sb82u7PdAX5bKibf84UMhSCFQAAQCZnn/X9YadRo/j3WYeHLV31++/Sb7+52+Bt69bEn9M6Oexxtp1MiRLxA5fd5s2b25tSZXO8bL1gO8fqNgCRjGAFAACAk87jsuIWtiUMXcamGFmxjISBy45ZL5gVzDgZC2a2rV3rP2KLcBU84byCBV3I8m8WthJ+bbc2es/OZW1qnG4EKwAAAIRUOd1fQCMxBw+6UvEWsv76y23+r/23NpzQerhOxqqu22bDFJPTA2fr/1rIKlLEbaf62sKYDZVkhB5Si2AFAACAdGOVA/09XkmxUGVLSFnI2rgxVuvX79GBAwW0dWuMd9w269WyWyvEdyo2Z2zHDrelpr0WsGzzh63E9v1f2zrBFi6DN1u2yn/LGsGZB8EKAAAAYeUvdGGbFdbYuvWASpTIryxZTlxEy4rp+UNWcOCyzYYdWpjavj0QrGyZqpSwHjbbkpo7lpqgFhy2gsOXf41gOyd4O9Ux/xrBtgV/nXA/+Gt7j1njN30RrAAAABA1LIzYGlq2JYdVGLdwlTBwJfzaSsvbZsMNg78Odckpf1Cz1wgnC1VW/t4Clv82eDvVMZuz5l/zN6Vfm+Db5HxtatWSHnpIUYNgBQAAgAzLwkGxYm5LKRtSaOt7JQxc/n3bbA1bO8eKeARvCY8F74djfWD/8lm2RYujRxVVCFYAAABAIqznxD90zxZDTquAY2v8WtCyW3+Pln9LzjFbK9gfkpL6OrF922w+m20WWvxfJ+eYf73fhGv4IoBgBQAAAJzGsOafKxWt/CHLH7SS+vrY8UqP/jBmt8n52n8bbe8RwQoAAABAisKhf+4VAlg6DQAAAABCRLACAAAAgBARrAAAAAAgRAQrAAAAAAgRwQoAAAAAQkSwAgAAAIAQEawAAAAAIEQEKwAAAAAIEcEKAAAAAEJEsAIAAACAEBGsAAAAACBEBCsAAAAACBHBCgAAAABCRLACAAAAgBARrAAAAAAgRAQrAAAAAAgRwQoAAAAAQpQt1CfIiHw+n3e7e/fucDdFsbGx2rNnj3LlyqUsWcjBSBmuH6QW1w5CwfWDUHD9INKuH38m8GeEpBCsEmE/DFOuXLlwNwUAAABAhGSEggULJnl/jO9U0SuTJt1NmzYpf/78iomJCWtbLCFbwPvzzz9VoECBsLYF0YfrB6nFtYNQcP0gFFw/iLTrx+KShaoyZcqctBeMHqtE2BtWtmxZRRK7MPjlgtTi+kFqce0gFFw/CAXXDyLp+jlZT5UfA1cBAAAAIEQEKwAAAAAIEcEqwuXMmVNPPPGEdwukFNcPUotrB6Hg+kEouH4QrdcPxSsAAAAAIET0WAEAAABAiAhWAAAAABAighUAAAAAhIhgBQAAAAAhIlhFsNdff11nnXWWcuXKpcsuu0yrV68Od5MQgZYtW6ZWrVp5q4HHxMRo2rRp8e63+jSPP/64Spcurdy5c6tx48b65ZdfwtZeRJaBAweqZs2ayp8/v0qUKKHrrrtO69ati3fOwYMH1aNHDxUtWlT58uVTu3bt9M8//4StzYgMb775pqpUqRK3CGft2rU1e/bsuPu5bpASgwYN8v4f1rNnz7hjXENIypNPPuldL8FbpUqVwn7tEKwi1AcffKDevXt75SLXrl2rSy65RE2bNtXWrVvD3TREmH379nnXhwXxxLzwwgsaNmyYhg8frs8//1x58+b1riX7pQMsXbrU+5/PqlWrNH/+fB05ckRNmjTxriu/Xr16acaMGZo0aZJ3/qZNm9S2bduwthvhV7ZsWe/D8Jdffqk1a9aoYcOGat26tX744Qfvfq4bJNcXX3yht956ywvqwbiGcDIXXnihNm/eHLetWLEi/NeOlVtH5KlVq5avR48ecfvHjh3zlSlTxjdw4MCwtguRzf5JT506NW4/NjbWV6pUKd/gwYPjju3cudOXM2dO3/vvvx+mViKSbd261buOli5dGne9ZM+e3Tdp0qS4c3766SfvnJUrV4axpYhEhQsX9r399ttcN0i2PXv2+M4991zf/PnzffXq1fPdf//93nGuIZzME0884bvkkksSvS+c1w49VhHo8OHD3l8AbciWX5YsWbz9lStXhrVtiC6///67tmzZEu9aKliwoDe0lGsJidm1a5d3W6RIEe/WfhdZL1bwNWTDLc4880yuIcQ5duyYJk6c6PV02pBArhskl/WYt2jRIt61YriGcCo2rcGmQZx99tnq2LGjNm7cGPZrJ1u6PjtS5d9///X+J1WyZMl4x23/559/Dlu7EH0sVJnEriX/fYBfbGysN7/hyiuv1EUXXeQds+skR44cKlSoULxzuYZgvvvuOy9I2dBim8cwdepUVa5cWV9//TXXDU7JwrhNd7ChgAnxuwcnY38gHj16tM4//3xvGOBTTz2lOnXq6Pvvvw/rtUOwAgDE/eXY/qcUPE4dOBn7UGMhyno6J0+erK5du3rzGYBT+fPPP3X//fd7czutSBeQEs2bN4/72ubmWdAqX768PvzwQ69QV7gwFDACFStWTFmzZj2heontlypVKmztQvTxXy9cSziVe+65RzNnztTixYu9ogR+dp3Y8OSdO3fGO59rCMb+KlyxYkVVr17dqzBphXReeeUVrhuckg3XsoJcl156qbJly+ZtFsqt2JJ9bb0LXENILuudOu+887R+/fqw/v4hWEXo/6jsf1ILFy6MN0TH9m3IBZBcFSpU8H6JBF9Lu3fv9qoDci3BWM0TC1U2hGvRokXeNRPMfhdlz5493jVk5dhtLDvXEBKy/1cdOnSI6wan1KhRI28oqfV4+rcaNWp4c2X8X3MNIbn27t2rX3/91VtaJpy/fxgKGKGs1LoNqbBfLLVq1dLQoUO9ScHdunULd9MQgb9M7C80wQUr7H9KVnzAJmranJlnnnlG5557rvehuX///t5kT1uvCLDhfxMmTND06dO9taz848+tyIkNp7DbW2+91fudZNeUrVd07733ev9zuvzyy8PdfIRR3759veE49ntmz5493nW0ZMkSzZ07l+sGp2S/b/xzOf1sORBbd8h/nGsISenTp4+3hqcN/7NS6rY8kY32uummm8L7+yddaw4iJK+++qrvzDPP9OXIkcMrv75q1apwNwkRaPHixV4J0YRb165d40qu9+/f31eyZEmvzHqjRo1869atC3ezESESu3ZsGzVqVNw5Bw4c8N19991eKe08efL42rRp49u8eXNY243wu+WWW3zly5f3/h9VvHhx73fLvHnz4u7nukFKBZdbN1xDSEr79u19pUuX9n7/nHHGGd7++vXrw37txNh/0je6AQAAAEDGxhwrAAAAAAgRwQoAAAAAQkSwAgAAAIAQEawAAAAAIEQEKwAAAAAIEcEKAAAAAEJEsAIAAACAEBGsAAAAACBEBCsAANLB6NGjFRMTozVr1oS7KQCA04BgBQCI+vCS1LZq1apwNxEAkElkC3cDAAAI1YABA1ShQoUTjlesWDEs7QEAZD4EKwBA1GvevLlq1KgR7mYAADIxhgICADK0P/74wxsW+OKLL2rIkCEqX768cufOrXr16un7778/4fxFixapTp06yps3rwoVKqTWrVvrp59+OuG8v//+W7feeqvKlCmjnDlzej1m3bt31+HDh+Odd+jQIfXu3VvFixf3nrNNmzbatm1bun7PAIDTjx4rAEDU27Vrl/799994xyxMFS1aNG5/7Nix2rNnj3r06KGDBw/qlVdeUcOGDfXdd9+pZMmS3jkLFizwer/OPvtsPfnkkzpw4IBeffVVXXnllVq7dq3OOuss77xNmzapVq1a2rlzp+644w5VqlTJC1qTJ0/W/v37lSNHjrjXvffee1W4cGE98cQTXsgbOnSo7rnnHn3wwQen7f0BAKQ/ghUAIOo1btz4hGPWi2QBym/9+vX65ZdfdMYZZ3j7zZo102WXXabnn39eL7/8snfswQcfVJEiRbRy5Urv1lx33XWqVq2aF4zGjBnjHevbt6+2bNmizz//PN4QRJvr5fP54rXDwt28efO8oGdiY2M1bNgwLwwWLFgwXd4PAMDpR7ACAES9119/Xeedd168Y1mzZo23bwHJH6qM9ThZsJo1a5YXrDZv3qyvv/5aDz30UFyoMlWqVNHVV1/tnecPRtOmTVOrVq0SndflD1B+1qMVfMyGGdqQxA0bNnjPDQDIGAhWAICoZyHpVMUrzj333BOOWRj78MMPva8t6Jjzzz//hPMuuOACzZ07V/v27dPevXu1e/duXXTRRclq25lnnhlv34YFmv/++y9ZjwcARAeKVwAAkI4S9pz5JRwyCACIbvRYAQAyBZtfldD//ve/uIIUVi3QrFu37oTzfv75ZxUrVsyr6mcVBQsUKJBoRUEAQOZFjxUAIFOweVFWuc9v9erVXvEJqwJoSpcurapVq3oFKqzan58FKCs+cc0113j7WbJk8eZrzZgxQ2vWrDnhdeiJAoDMiR4rAEDUmz17tterlNAVV1zhBSFTsWJFXXXVVd5aU7a2lJU9t4p9VqzCb/DgwV7Qql27trdGlb/culXvs/Lrfs8995wXtmwtLCtOYXOwrPjFpEmTtGLFCm/9KwBA5kKwAgBEvccffzzR46NGjVL9+vW9r7t06eKFLAtUW7du9QpevPbaa15PVXDZ9jlz5nil1e05s2fP7oUnK8luCwD7WXVB6+3q37+/3nvvPa+YhR2zUJYnT57T8B0DACJNjI8xCwCADMwW5bVQZL1Rffr0CXdzAAAZFHOsAAAAACBEBCsAAAAACBHBCgAAAABCxBwrAAAAAAgRPVYAAAAAECKCFQAAAACEiGAFAAAAACEiWAEAAABAiAhWAAAAABAighUAAAAAhIhgBQAAAAAhIlgBAAAAgELz/262xKDeiNJpAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Generating thermostable sequences...\n",
      "\n",
      "Generated sequence for 70.0C:\n",
      "Length: 300\n",
      "Sequence: LLFFLFENVRAHEAVGALVWNRLGALGVHRGKVLMLLITGRPEHEPLAATRRFAAIQVRIGVAEHAPAWRAAGRYEGDGIPRGPLVFANALERRAPVGLL...\n",
      "\n",
      "Generated sequence for 70.0C:\n",
      "Length: 300\n",
      "Sequence: MGKDVGRVGVALTVKPEQAGREPGGAMALLRVELAGRPFAANEVHVTMKGVLFAEGQRYPLILLLGQDGGRALAGSGERGDGKVEDAAELERAEAAFREM...\n",
      "\n",
      "Generated sequence for 70.0C:\n",
      "Length: 300\n",
      "Sequence: LKAKAVPAEPFRLGKEAQLTALVEKESLSVEKVRDTRANLSKTPVFLVINEKPRTELTIHLAPVLYDSIVGAPTLKVPVVALFNAEKLVLTEETSGDRDF...\n",
      "\n",
      "Generated sequence for 80.0C:\n",
      "Length: 300\n",
      "Sequence: LDLAPLTGIEAQSAELVEWRDPMANSDAPEKLREGAIVRYQREVTDRMAYSNAQLGRSPREDIYEGVAVIPPVPHVERDEPRRQGLYSPYVPISAARPAG...\n",
      "\n",
      "Generated sequence for 80.0C:\n",
      "Length: 300\n",
      "Sequence: PSSMLKRVVQESVPPNKLGVNRNTVGIRVDADELAADRGLVFWDEEAAVFLKRNAAHSARVEREELAELLAKLNEIGLRSTWLLNVIEDRNRHGEIIVPA...\n",
      "\n",
      "Generated sequence for 80.0C:\n",
      "Length: 300\n",
      "Sequence: ASLKVHTSKYGVVNQYAMRRRGNLNELVEAFGLFRVENEVEPILIGDQDFLARVRVAAQLRMKKARASEPERQIRGPEAMGQGFAKGMHYVKFRIKLPGA...\n",
      "\n",
      "Generated sequence for 90.0C:\n",
      "Length: 299\n",
      "Sequence: ALDHYSRTREGKRGEGGGLQPGVLQDWRDPAFMQALRTERKELPPEPLEEIALQVQASGELLVTGEAQAAPELFTFEEFKMLDPSAHRHGRHKVVGLAAA...\n",
      "\n",
      "Generated sequence for 90.0C:\n",
      "Length: 300\n",
      "Sequence: EVRPEEMVLPPETLTKLVWRFEVLEELRMVLGKLGQLWPPDAVSEWNLYRVYLLLRRVVIRRDVFLPVPEDFLGEAYVRRPAAALGAFVGALTEAREAMA...\n",
      "\n",
      "Generated sequence for 90.0C:\n",
      "Length: 300\n",
      "Sequence: AVVEVKLGVSPLVAYAASALVGVHPLHLAYLDMLMLSEGTFVAGPYVVTSCVLGLPAAGEVVEFEVANEAEVQLQTLAERVAGPTGQFARLEDLLSGDKP...\n",
      "\n",
      "Model saved as 'rubisco_diffusion_model.pth'\n",
      "Training completed!\n"
     ]
    }
   ],
   "source": [
    "# Configuration\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Load data\n",
    "csv_path = \"uniprot_with_Tm.csv\"\n",
    "sequences, temperatures = load_protein_data(csv_path)\n",
    "\n",
    "# Create vocabulary\n",
    "aa_to_idx, idx_to_aa = create_amino_acid_vocab()\n",
    "\n",
    "# Split data\n",
    "train_sequences, val_sequences, train_temps, val_temps = train_test_split(\n",
    "    sequences, temperatures, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# Create model components\n",
    "model_components = create_model_components(\n",
    "    vocab_size=21,\n",
    "    d_model=256,\n",
    "    num_heads=8,\n",
    "    num_layers=6,\n",
    "    d_ff=1024,\n",
    "    dropout=0.1\n",
    ")\n",
    "\n",
    "# Create diffusion schedule\n",
    "diffusion_schedule = create_diffusion_schedule(num_timesteps=1000)\n",
    "\n",
    "# Count parameters\n",
    "total_params = 0\n",
    "def count_params(component):\n",
    "    global total_params\n",
    "    if hasattr(component, 'parameters'):\n",
    "        total_params += sum(p.numel() for p in component.parameters())\n",
    "    elif isinstance(component, dict):\n",
    "        for v in component.values():\n",
    "            count_params(v)\n",
    "    elif isinstance(component, list):\n",
    "        for item in component:\n",
    "            count_params(item)\n",
    "\n",
    "count_params(model_components)\n",
    "print(f\"Model has {total_params} parameters\")\n",
    "\n",
    "# Prepare data\n",
    "train_data = {\n",
    "    'sequences': train_sequences,\n",
    "    'temperatures': train_temps,\n",
    "    'amino_acid_to_idx': aa_to_idx\n",
    "}\n",
    "\n",
    "val_data = {\n",
    "    'sequences': val_sequences,\n",
    "    'temperatures': val_temps,\n",
    "    'amino_acid_to_idx': aa_to_idx\n",
    "}\n",
    "\n",
    "# Train model\n",
    "print(\"Starting training...\")\n",
    "train_losses, val_losses = train_diffusion_model(\n",
    "    model_components, train_data, val_data, diffusion_schedule,\n",
    "    num_epochs=50, learning_rate=1e-4, device=device\n",
    ")\n",
    "\n",
    "# Plot training curves\n",
    "plot_training_curves(train_losses, val_losses, save_path=\"training_curves.png\")\n",
    "\n",
    "# Generate new sequences\n",
    "print(\"\\nGenerating thermostable sequences...\")\n",
    "target_temperatures = [70.0, 80.0, 90.0]\n",
    "generated_sequences = generate_sequences(\n",
    "    model_components, diffusion_schedule, target_temperatures,\n",
    "    sequence_length=300, num_samples=3, device=device, idx_to_aa=idx_to_aa\n",
    ")\n",
    "\n",
    "# Display generated sequences\n",
    "for i, seq in enumerate(generated_sequences):\n",
    "    temp_idx = i // 3\n",
    "    print(f\"\\nGenerated sequence for {target_temperatures[temp_idx]}C:\")\n",
    "    print(f\"Length: {len(seq)}\")\n",
    "    print(f\"Sequence: {seq[:100]}...\" if len(seq) > 100 else f\"Sequence: {seq}\")\n",
    "\n",
    "# Save model components\n",
    "save_data = {\n",
    "    'model_components': model_components,\n",
    "    'diffusion_schedule': diffusion_schedule,\n",
    "    'aa_to_idx': aa_to_idx,\n",
    "    'idx_to_aa': idx_to_aa,\n",
    "    'config': {\n",
    "        'vocab_size': 21,\n",
    "        'd_model': 256,\n",
    "        'num_heads': 8,\n",
    "        'num_layers': 6,\n",
    "        'd_ff': 1024,\n",
    "        'dropout': 0.1\n",
    "    }\n",
    "}\n",
    "\n",
    "torch.save(save_data, 'rubisco_diffusion_model.pth')\n",
    "print(\"\\nModel saved as 'rubisco_diffusion_model.pth'\")\n",
    "print(\"Training completed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74b8aac4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
